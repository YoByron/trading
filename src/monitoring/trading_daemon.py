#!/usr/bin/env python3
"""
Trading System Monitoring Daemon

Continuously monitors the trading system for:
1. Workflow failures
2. Zero trades during market hours
3. Performance degradation
4. System health issues

Alerts via:
- Console logging
- Slack webhook (if configured)
- GitHub Issues (if configured)
- Email (if configured)

Usage:
    # Run as daemon
    python3 -m src.monitoring.trading_daemon
    
    # Or with systemd
    systemctl start trading-monitor

Created: Dec 11, 2025 (after zero-trade incident)
"""

import json
import logging
import os
import signal
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Optional
import threading

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/trading_daemon.log', mode='a'),
    ]
)
logger = logging.getLogger('TradingDaemon')


@dataclass
class Alert:
    """An alert generated by the monitoring daemon."""
    
    level: str  # "info", "warning", "critical"
    type: str
    message: str
    timestamp: str
    details: dict = field(default_factory=dict)
    notified: bool = False


@dataclass
class DaemonConfig:
    """Configuration for the monitoring daemon."""
    
    check_interval_seconds: int = 300  # 5 minutes
    market_open_hour: int = 9
    market_open_minute: int = 30
    market_close_hour: int = 16
    market_close_minute: int = 0
    min_daily_trades: int = 1
    max_consecutive_failures: int = 3
    data_dir: str = "data"
    github_token: Optional[str] = None
    slack_webhook: Optional[str] = None
    email_recipient: Optional[str] = None


class TradingDaemon:
    """
    Monitoring daemon that continuously watches the trading system.
    
    Responsibilities:
    1. Check if trades are being executed during market hours
    2. Monitor GitHub Actions workflow status
    3. Detect system health issues
    4. Alert on anomalies
    5. Record incidents to RAG for learning
    """
    
    def __init__(self, config: Optional[DaemonConfig] = None):
        self.config = config or DaemonConfig()
        self.running = False
        self.alerts: list[Alert] = []
        self.last_check: Optional[datetime] = None
        self.consecutive_failures = 0
        
        # Create logs directory
        Path("logs").mkdir(exist_ok=True)
        
        # Signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, self._handle_shutdown)
        signal.signal(signal.SIGTERM, self._handle_shutdown)
        
        logger.info("Trading daemon initialized")
    
    def _handle_shutdown(self, signum, frame):
        """Handle shutdown signals gracefully."""
        logger.info(f"Received signal {signum}, shutting down...")
        self.running = False
    
    def start(self):
        """Start the monitoring daemon."""
        self.running = True
        logger.info("=" * 60)
        logger.info("TRADING DAEMON STARTED")
        logger.info(f"Check interval: {self.config.check_interval_seconds}s")
        logger.info("=" * 60)
        
        while self.running:
            try:
                self._run_checks()
                self.last_check = datetime.now(timezone.utc)
                
                # Sleep in small intervals for responsiveness
                for _ in range(self.config.check_interval_seconds):
                    if not self.running:
                        break
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"Error in daemon loop: {e}")
                self.consecutive_failures += 1
                
                if self.consecutive_failures >= self.config.max_consecutive_failures:
                    self._alert(
                        level="critical",
                        type="daemon_failure",
                        message=f"Daemon failed {self.consecutive_failures} times consecutively",
                        details={"error": str(e)}
                    )
                
                time.sleep(60)  # Wait before retry
        
        logger.info("Trading daemon stopped")
    
    def _run_checks(self):
        """Run all monitoring checks."""
        now = datetime.now(timezone.utc)
        et_time = now - timedelta(hours=5)  # Convert to ET
        
        logger.info(f"Running checks at {now.isoformat()}")
        
        # Check 1: Market hours trade monitoring
        if self._is_market_hours(et_time):
            self._check_trades_executing()
        
        # Check 2: GitHub workflow status
        self._check_workflow_status()
        
        # Check 3: System health
        self._check_system_health()
        
        # Check 4: Performance metrics
        self._check_performance()
        
        # Process and send alerts
        self._process_alerts()
        
        # Reset failure counter on successful check
        self.consecutive_failures = 0
    
    def _is_market_hours(self, et_time: datetime) -> bool:
        """Check if current time is during market hours (ET)."""
        # Skip weekends
        if et_time.weekday() >= 5:
            return False
        
        market_open = et_time.replace(
            hour=self.config.market_open_hour,
            minute=self.config.market_open_minute,
            second=0
        )
        market_close = et_time.replace(
            hour=self.config.market_close_hour,
            minute=self.config.market_close_minute,
            second=0
        )
        
        return market_open <= et_time <= market_close
    
    def _check_trades_executing(self):
        """Check if trades are being executed today."""
        today = datetime.now(timezone.utc).strftime("%Y-%m-%d")
        trades_file = Path(self.config.data_dir) / f"trades_{today}.json"
        
        if not trades_file.exists():
            # No trades file for today
            now = datetime.now(timezone.utc)
            et_time = now - timedelta(hours=5)
            
            # Only alert if we're past 10:30 AM ET (1 hour after open)
            if et_time.hour >= 10 and et_time.minute >= 30:
                self._alert(
                    level="critical",
                    type="no_trades_today",
                    message=f"NO TRADES FILE EXISTS FOR {today}",
                    details={
                        "expected_file": str(trades_file),
                        "current_time_et": et_time.strftime("%H:%M:%S"),
                        "similar_incident": "ll_009_ci_syntax_failure_dec11",
                    }
                )
        else:
            try:
                with open(trades_file) as f:
                    trades = json.load(f)
                
                if len(trades) == 0:
                    self._alert(
                        level="critical",
                        type="zero_trades",
                        message=f"Trades file exists but is empty for {today}",
                        details={"file": str(trades_file)}
                    )
                else:
                    logger.info(f"‚úÖ {len(trades)} trades executed today")
                    
            except json.JSONDecodeError as e:
                self._alert(
                    level="warning",
                    type="corrupt_trades_file",
                    message=f"Trades file is corrupt: {e}",
                    details={"file": str(trades_file)}
                )
    
    def _check_workflow_status(self):
        """Check GitHub Actions workflow status."""
        if not self.config.github_token:
            return
        
        try:
            import urllib.request
            
            url = "https://api.github.com/repos/IgorGanapolsky/trading/actions/runs?per_page=5"
            headers = {
                "Authorization": f"token {self.config.github_token}",
                "Accept": "application/vnd.github.v3+json",
            }
            
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=30) as response:
                data = json.loads(response.read().decode())
            
            # Check for recent failures
            for run in data.get("workflow_runs", []):
                if run.get("conclusion") == "failure":
                    # Check if it's recent (within last hour)
                    created = datetime.fromisoformat(run["created_at"].replace("Z", "+00:00"))
                    if datetime.now(timezone.utc) - created < timedelta(hours=1):
                        self._alert(
                            level="critical",
                            type="workflow_failure",
                            message=f"Workflow '{run['name']}' FAILED",
                            details={
                                "workflow": run["name"],
                                "url": run["html_url"],
                                "created_at": run["created_at"],
                            }
                        )
                        
        except Exception as e:
            logger.warning(f"Could not check workflow status: {e}")
    
    def _check_system_health(self):
        """Check overall system health."""
        # Check 1: Critical files exist and have valid syntax
        critical_files = [
            "src/execution/alpaca_executor.py",
            "src/orchestrator/main.py",
            "src/risk/trade_gateway.py",
        ]
        
        import ast
        
        for filepath in critical_files:
            path = Path(filepath)
            if path.exists():
                try:
                    with open(path) as f:
                        ast.parse(f.read())
                except SyntaxError as e:
                    self._alert(
                        level="critical",
                        type="syntax_error",
                        message=f"SYNTAX ERROR in {filepath}: {e}",
                        details={
                            "file": filepath,
                            "line": e.lineno,
                            "similar_incident": "ll_009",
                        }
                    )
    
    def _check_performance(self):
        """Check trading performance metrics."""
        # Load recent performance
        perf_file = Path(self.config.data_dir) / "performance_log.json"
        if not perf_file.exists():
            return
        
        try:
            with open(perf_file) as f:
                history = json.load(f)
            
            if len(history) < 3:
                return
            
            # Check for negative streak
            recent = history[-3:]
            if all(h.get("pl", 0) < 0 for h in recent):
                self._alert(
                    level="warning",
                    type="losing_streak",
                    message="3 consecutive losing days",
                    details={
                        "recent_pls": [h.get("pl", 0) for h in recent]
                    }
                )
                
        except Exception as e:
            logger.warning(f"Could not check performance: {e}")
    
    def _alert(self, level: str, type: str, message: str, details: dict = None):
        """Create an alert."""
        alert = Alert(
            level=level,
            type=type,
            message=message,
            timestamp=datetime.now(timezone.utc).isoformat(),
            details=details or {},
        )
        
        self.alerts.append(alert)
        
        # Log immediately
        log_method = {
            "info": logger.info,
            "warning": logger.warning,
            "critical": logger.critical,
        }.get(level, logger.info)
        
        emoji = {"info": "‚ÑπÔ∏è", "warning": "‚ö†Ô∏è", "critical": "üö®"}.get(level, "")
        log_method(f"{emoji} ALERT [{type}]: {message}")
    
    def _process_alerts(self):
        """Process and send pending alerts."""
        critical_alerts = [a for a in self.alerts if a.level == "critical" and not a.notified]
        
        if not critical_alerts:
            return
        
        # Send notifications
        for alert in critical_alerts:
            self._send_notification(alert)
            alert.notified = True
        
        # Record to RAG for learning
        self._record_to_rag(critical_alerts)
    
    def _send_notification(self, alert: Alert):
        """Send alert notification via configured channels."""
        # Slack webhook
        if self.config.slack_webhook:
            try:
                import urllib.request
                
                payload = {
                    "text": f"üö® *{alert.type}*\n{alert.message}",
                    "attachments": [{
                        "color": "danger",
                        "fields": [
                            {"title": k, "value": str(v), "short": True}
                            for k, v in alert.details.items()
                        ]
                    }]
                }
                
                data = json.dumps(payload).encode()
                req = urllib.request.Request(
                    self.config.slack_webhook,
                    data=data,
                    headers={"Content-Type": "application/json"}
                )
                urllib.request.urlopen(req, timeout=10)
                logger.info(f"Slack notification sent for {alert.type}")
                
            except Exception as e:
                logger.error(f"Failed to send Slack notification: {e}")
        
        # GitHub Issue (for critical issues)
        if self.config.github_token and alert.level == "critical":
            try:
                import urllib.request
                
                issue_body = f"""## Automated Alert: {alert.type}

**Message:** {alert.message}

**Timestamp:** {alert.timestamp}

**Details:**
```json
{json.dumps(alert.details, indent=2)}
```

---
*This issue was created automatically by the Trading Daemon.*
"""
                
                payload = {
                    "title": f"üö® [{alert.type}] {alert.message[:50]}...",
                    "body": issue_body,
                    "labels": ["automated", "alert", alert.level],
                }
                
                url = "https://api.github.com/repos/IgorGanapolsky/trading/issues"
                headers = {
                    "Authorization": f"token {self.config.github_token}",
                    "Accept": "application/vnd.github.v3+json",
                }
                
                data = json.dumps(payload).encode()
                req = urllib.request.Request(url, data=data, headers=headers)
                urllib.request.urlopen(req, timeout=10)
                logger.info(f"GitHub issue created for {alert.type}")
                
            except Exception as e:
                logger.error(f"Failed to create GitHub issue: {e}")
    
    def _record_to_rag(self, alerts: list[Alert]):
        """Record alerts to RAG for learning."""
        try:
            from src.verification.rag_safety_checker import RAGSafetyChecker
            
            checker = RAGSafetyChecker()
            for alert in alerts:
                checker.record_incident(
                    category="daemon_alert",
                    title=f"Daemon Alert: {alert.type}",
                    description=alert.message,
                    root_cause="Automated detection",
                    prevention="Monitor and address root cause",
                    severity=alert.level,
                    tags=["daemon", "automated", alert.type],
                )
                
        except Exception as e:
            logger.warning(f"Could not record to RAG: {e}")
    
    def get_status(self) -> dict:
        """Get current daemon status."""
        return {
            "running": self.running,
            "last_check": self.last_check.isoformat() if self.last_check else None,
            "consecutive_failures": self.consecutive_failures,
            "pending_alerts": len([a for a in self.alerts if not a.notified]),
            "total_alerts": len(self.alerts),
        }


def main():
    """CLI entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Trading System Monitoring Daemon")
    parser.add_argument("--interval", type=int, default=300, help="Check interval in seconds")
    parser.add_argument("--github-token", type=str, help="GitHub PAT for notifications")
    parser.add_argument("--slack-webhook", type=str, help="Slack webhook URL")
    parser.add_argument("--once", action="store_true", help="Run once and exit")
    args = parser.parse_args()
    
    config = DaemonConfig(
        check_interval_seconds=args.interval,
        github_token=args.github_token or os.environ.get("GITHUB_TOKEN"),
        slack_webhook=args.slack_webhook or os.environ.get("SLACK_WEBHOOK"),
    )
    
    daemon = TradingDaemon(config)
    
    if args.once:
        daemon._run_checks()
        daemon._process_alerts()
        
        # Print status
        status = daemon.get_status()
        print(f"\nAlerts: {status['total_alerts']}")
        for alert in daemon.alerts:
            emoji = {"info": "‚ÑπÔ∏è", "warning": "‚ö†Ô∏è", "critical": "üö®"}.get(alert.level, "")
            print(f"  {emoji} [{alert.type}] {alert.message}")
    else:
        daemon.start()


if __name__ == "__main__":
    main()
