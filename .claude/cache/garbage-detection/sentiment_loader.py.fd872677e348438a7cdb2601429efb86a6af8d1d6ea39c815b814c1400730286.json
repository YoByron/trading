{
  "dead_imports": [],
  "commented_blocks": [],
  "empty_functions": [],
  "unused_variables": [
    {
      "line": 47,
      "variable": "NEUTRAL_LOW"
    },
    {
      "line": 48,
      "variable": "NEUTRAL_HIGH"
    }
  ],
  "all_functions": [
    {
      "name": "_load_source_from_sqlite",
      "line": 56,
      "code": "def _load_source_from_sqlite(source: str, date_str: str) -> Optional[Dict]:\n    \"\"\"\n    Load sentiment snapshot from SQLite store when JSON cache is missing.\n\n    Args:\n        source: Data source identifier (\"reddit\" or \"news\")\n        date_str: Date string (YYYY-MM-DD)\n\n    Returns:\n        Sentiment dict matching cached JSON structure, or None if unavailable.\n    \"\"\"\n    if _SQLITE_STORE is None:\n        return None\n    rows = list(_SQLITE_STORE.fetch_by_source_date(source=source, snapshot_date=date_str))\n    if not rows:\n        return None\n    sentiment_by_ticker = {}\n    for row in rows:\n        metadata = json.loads(row['metadata'])\n        sentiment_by_ticker[row['ticker']] = metadata\n    meta = {'date': date_str, 'timestamp': rows[0]['created_at'], 'sources': [source], 'tickers_analyzed': len(sentiment_by_ticker), 'store_backfill': True}\n    if source == 'reddit':\n        meta.update({'subreddits': [], 'total_tickers': len(sentiment_by_ticker)})\n    return {'meta': meta, 'sentiment_by_ticker': sentiment_by_ticker}"
    },
    {
      "name": "normalize_sentiment_score",
      "line": 99,
      "code": "def normalize_sentiment_score(score: float, source: str) -> float:\n    \"\"\"\n    Normalize sentiment score from various sources to 0-100 scale.\n\n    Different sources use different scales:\n    - Reddit: Raw scores (can be large positive/negative integers)\n    - News: -100 to +100 scale\n    - Alpha Vantage: -1 to +1 scale\n\n    We normalize everything to 0-100 where:\n    - 0 = maximally bearish\n    - 50 = neutral\n    - 100 = maximally bullish\n\n    Args:\n        score: Raw sentiment score from source\n        source: Source identifier (\"reddit\", \"news\", \"alphavantage\")\n\n    Returns:\n        Normalized score on 0-100 scale\n    \"\"\"\n    if source == 'reddit':\n        clamped = max(-100, min(100, score))\n        normalized = (clamped + 100) / 2\n        return normalized\n    elif source == 'news':\n        normalized = (score + 100) / 2\n        return normalized\n    elif source == 'alphavantage':\n        normalized = (score + 1) * 50\n        return normalized\n    else:\n        return max(0, min(100, score))"
    },
    {
      "name": "load_latest_sentiment",
      "line": 142,
      "code": "def load_latest_sentiment(date: Optional[str]=None, fallback_days: int=7) -> Dict:\n    \"\"\"\n    Load the most recent sentiment data from cache files.\n\n    Combines data from:\n    - Reddit sentiment (data/sentiment/reddit_YYYY-MM-DD.json)\n    - News sentiment (data/sentiment/news_YYYY-MM-DD.json)\n\n    Args:\n        date: Specific date to load (YYYY-MM-DD), or None for today\n        fallback_days: Days to look back if today's data not found (default: 7)\n\n    Returns:\n        Dict with combined sentiment data:\n        {\n            \"meta\": {\n                \"date\": \"2025-11-09\",\n                \"timestamp\": \"2025-11-09T08:00:00\",\n                \"sources\": [\"reddit\", \"news\"],\n                \"freshness\": \"fresh|stale|missing\"\n            },\n            \"sentiment_by_ticker\": {\n                \"SPY\": {\n                    \"score\": 65.5,  # 0-100 normalized scale\n                    \"confidence\": \"high|medium|low\",\n                    \"sources\": {\n                        \"reddit\": {\"score\": 120, \"mentions\": 45, ...},\n                        \"news\": {\"score\": 35, \"articles\": 12, ...}\n                    },\n                    \"market_regime\": \"risk_on|risk_off|neutral\"\n                },\n                ...\n            }\n        }\n    \"\"\"\n    if date is None:\n        target_date = datetime.now()\n    else:\n        target_date = datetime.strptime(date, '%Y-%m-%d')\n    logger.info(f\"Loading sentiment data for {target_date.strftime('%Y-%m-%d')}\")\n    reddit_data = None\n    news_data = None\n    days_searched = 0\n    for days_back in range(fallback_days + 1):\n        search_date = target_date - timedelta(days=days_back)\n        date_str = search_date.strftime('%Y-%m-%d')\n        days_searched = days_back\n        if reddit_data is None:\n            reddit_file = SENTIMENT_DIR / f'reddit_{date_str}.json'\n            if reddit_file.exists():\n                try:\n                    with open(reddit_file, 'r') as f:\n                        reddit_data = json.load(f)\n                        logger.info(f'Loaded Reddit sentiment from {reddit_file}')\n                except Exception as e:\n                    logger.error(f'Failed to load Reddit sentiment: {e}')\n            elif _SQLITE_STORE:\n                reddit_data = _load_source_from_sqlite('reddit', date_str)\n                if reddit_data:\n                    logger.info('Loaded Reddit sentiment from SQLite fallback')\n        if news_data is None:\n            news_file = SENTIMENT_DIR / f'news_{date_str}.json'\n            if news_file.exists():\n                try:\n                    with open(news_file, 'r') as f:\n                        news_data = json.load(f)\n                        logger.info(f'Loaded news sentiment from {news_file}')\n                except Exception as e:\n                    logger.error(f'Failed to load news sentiment: {e}')\n            elif _SQLITE_STORE:\n                news_data = _load_source_from_sqlite('news', date_str)\n                if news_data:\n                    logger.info('Loaded news sentiment from SQLite fallback')\n        if reddit_data and news_data:\n            break\n    if days_searched == 0:\n        freshness = 'fresh'\n    elif days_searched <= 3:\n        freshness = 'stale'\n    else:\n        freshness = 'old'\n    if not reddit_data and (not news_data):\n        logger.warning('No sentiment data found!')\n        return {'meta': {'date': target_date.strftime('%Y-%m-%d'), 'timestamp': datetime.now().isoformat(), 'sources': [], 'freshness': 'missing'}, 'sentiment_by_ticker': {}}\n    combined_sentiment = {}\n    sources_used = []\n    if reddit_data:\n        sources_used.append('reddit')\n        reddit_tickers = reddit_data.get('sentiment_by_ticker', {})\n        for ticker, data in reddit_tickers.items():\n            if ticker not in combined_sentiment:\n                combined_sentiment[ticker] = {'sources': {}, 'scores': [], 'confidences': []}\n            reddit_score = data.get('score', 0)\n            normalized_score = normalize_sentiment_score(reddit_score, 'reddit')\n            combined_sentiment[ticker]['sources']['reddit'] = {'raw_score': reddit_score, 'normalized_score': normalized_score, 'mentions': data.get('mentions', 0), 'confidence': data.get('confidence', 'low'), 'bullish_keywords': data.get('bullish_keywords', 0), 'bearish_keywords': data.get('bearish_keywords', 0)}\n            combined_sentiment[ticker]['scores'].append(normalized_score)\n            combined_sentiment[ticker]['confidences'].append(data.get('confidence', 'low'))\n    if news_data:\n        sources_used.append('news')\n        news_tickers = news_data.get('sentiment_by_ticker', {})\n        for ticker, ticker_obj in news_tickers.items():\n            if ticker not in combined_sentiment:\n                combined_sentiment[ticker] = {'sources': {}, 'scores': [], 'confidences': []}\n            news_score = ticker_obj.get('score', 0)\n            normalized_score = normalize_sentiment_score(news_score, 'news')\n            combined_sentiment[ticker]['sources']['news'] = {'raw_score': news_score, 'normalized_score': normalized_score, 'confidence': ticker_obj.get('confidence', 'low'), 'yahoo': ticker_obj.get('sources', {}).get('yahoo', {}), 'stocktwits': ticker_obj.get('sources', {}).get('stocktwits', {}), 'alphavantage': ticker_obj.get('sources', {}).get('alphavantage', {})}\n            combined_sentiment[ticker]['scores'].append(normalized_score)\n            combined_sentiment[ticker]['confidences'].append(ticker_obj.get('confidence', 'low'))\n    final_sentiment = {}\n    for ticker, data in combined_sentiment.items():\n        scores = data['scores']\n        confidences = data['confidences']\n        final_score = sum(scores) / len(scores) if scores else 50.0\n        confidence_map = {'low': 0, 'medium': 1, 'high': 2}\n        max_confidence = max((confidence_map.get(c, 0) for c in confidences))\n        confidence_reverse = {0: 'low', 1: 'medium', 2: 'high'}\n        final_confidence = confidence_reverse[max_confidence]\n        if final_score < VERY_BEARISH_THRESHOLD:\n            market_regime = 'risk_off'\n        elif final_score > VERY_BULLISH_THRESHOLD:\n            market_regime = 'risk_on'\n        else:\n            market_regime = 'neutral'\n        final_sentiment[ticker] = {'score': round(final_score, 2), 'confidence': final_confidence, 'sources': data['sources'], 'market_regime': market_regime}\n    return {'meta': {'date': target_date.strftime('%Y-%m-%d'), 'timestamp': datetime.now().isoformat(), 'sources': sources_used, 'freshness': freshness, 'days_old': days_searched}, 'sentiment_by_ticker': final_sentiment}"
    },
    {
      "name": "get_ticker_sentiment",
      "line": 356,
      "code": "def get_ticker_sentiment(ticker: str, sentiment_data: Optional[Dict]=None, default_score: float=50.0, default_confidence: str='low') -> Tuple[float, str, str]:\n    \"\"\"\n    Get sentiment score for a specific ticker.\n\n    Args:\n        ticker: Stock ticker symbol (e.g., \"SPY\", \"NVDA\")\n        sentiment_data: Pre-loaded sentiment data (optional - will load if None)\n        default_score: Default score if ticker not found (default: 50.0 = neutral)\n        default_confidence: Default confidence if ticker not found (default: \"low\")\n\n    Returns:\n        Tuple of (score, confidence, market_regime)\n        - score: Sentiment score on 0-100 scale\n        - confidence: \"low\", \"medium\", or \"high\"\n        - market_regime: \"risk_on\", \"risk_off\", or \"neutral\"\n    \"\"\"\n    if sentiment_data is None:\n        sentiment_data = load_latest_sentiment()\n    ticker_data = sentiment_data.get('sentiment_by_ticker', {}).get(ticker)\n    if not ticker_data:\n        logger.debug(f'No sentiment data for {ticker}, using default {default_score}')\n        if default_score < VERY_BEARISH_THRESHOLD:\n            default_regime = 'risk_off'\n        elif default_score > VERY_BULLISH_THRESHOLD:\n            default_regime = 'risk_on'\n        else:\n            default_regime = 'neutral'\n        return (default_score, default_confidence, default_regime)\n    score = ticker_data.get('score', default_score)\n    confidence = ticker_data.get('confidence', default_confidence)\n    market_regime = ticker_data.get('market_regime', 'neutral')\n    logger.debug(f'{ticker} sentiment: score={score}, confidence={confidence}, regime={market_regime}')\n    return (score, confidence, market_regime)"
    },
    {
      "name": "is_sentiment_fresh",
      "line": 408,
      "code": "def is_sentiment_fresh(sentiment_data: Dict, max_age_hours: int=MAX_AGE_HOURS) -> bool:\n    \"\"\"\n    Check if sentiment data is fresh (recent enough to use).\n\n    Args:\n        sentiment_data: Sentiment data dict\n        max_age_hours: Maximum age in hours (default: 24)\n\n    Returns:\n        True if data is fresh, False if stale\n    \"\"\"\n    freshness = sentiment_data.get('meta', {}).get('freshness', 'missing')\n    days_old = sentiment_data.get('meta', {}).get('days_old', 999)\n    if freshness == 'missing':\n        return False\n    hours_old = days_old * 24\n    return hours_old <= max_age_hours"
    },
    {
      "name": "get_market_regime",
      "line": 429,
      "code": "def get_market_regime(sentiment_data: Optional[Dict]=None) -> str:\n    \"\"\"\n    Get overall market regime based on SPY sentiment.\n\n    Market regimes:\n    - \"risk_on\": Bullish market, favorable for growth stocks\n    - \"risk_off\": Bearish market, defensive positioning needed\n    - \"neutral\": No clear trend, normal operation\n\n    Args:\n        sentiment_data: Pre-loaded sentiment data (optional)\n\n    Returns:\n        Market regime string\n    \"\"\"\n    spy_score, spy_confidence, spy_regime = get_ticker_sentiment('SPY', sentiment_data)\n    logger.info(f'Market regime: {spy_regime} (SPY sentiment: {spy_score}, confidence: {spy_confidence})')\n    return spy_regime"
    },
    {
      "name": "get_sentiment_summary",
      "line": 455,
      "code": "def get_sentiment_summary(sentiment_data: Optional[Dict]=None) -> Dict:\n    \"\"\"\n    Get a human-readable summary of sentiment data.\n\n    Args:\n        sentiment_data: Pre-loaded sentiment data (optional)\n\n    Returns:\n        Dict with summary statistics\n    \"\"\"\n    if sentiment_data is None:\n        sentiment_data = load_latest_sentiment()\n    meta = sentiment_data.get('meta', {})\n    tickers = sentiment_data.get('sentiment_by_ticker', {})\n    bullish = sum((1 for t in tickers.values() if t.get('score', 50) >= BULLISH_THRESHOLD))\n    bearish = sum((1 for t in tickers.values() if t.get('score', 50) <= BEARISH_THRESHOLD))\n    neutral = len(tickers) - bullish - bearish\n    high_conf = sum((1 for t in tickers.values() if t.get('confidence') == 'high'))\n    med_conf = sum((1 for t in tickers.values() if t.get('confidence') == 'medium'))\n    low_conf = sum((1 for t in tickers.values() if t.get('confidence') == 'low'))\n    return {'date': meta.get('date'), 'freshness': meta.get('freshness'), 'days_old': meta.get('days_old', 0), 'sources': meta.get('sources', []), 'total_tickers': len(tickers), 'bullish': bullish, 'bearish': bearish, 'neutral': neutral, 'high_confidence': high_conf, 'medium_confidence': med_conf, 'low_confidence': low_conf, 'market_regime': get_market_regime(sentiment_data)}"
    },
    {
      "name": "print_sentiment_summary",
      "line": 497,
      "code": "def print_sentiment_summary(sentiment_data: Optional[Dict]=None):\n    \"\"\"\n    Print a formatted summary of sentiment data.\n\n    Args:\n        sentiment_data: Pre-loaded sentiment data (optional)\n    \"\"\"\n    summary = get_sentiment_summary(sentiment_data)\n    print('\\n' + '=' * 80)\n    print('SENTIMENT SUMMARY')\n    print('=' * 80)\n    print(f\"Date: {summary['date']}\")\n    print(f\"Freshness: {summary['freshness'].upper()} ({summary['days_old']} days old)\")\n    print(f\"Sources: {', '.join(summary['sources'])}\")\n    print(f\"Market Regime: {summary['market_regime'].upper()}\")\n    print()\n    print(f\"Total Tickers: {summary['total_tickers']}\")\n    print(f\"  Bullish:  {summary['bullish']} ({summary['bullish'] / summary['total_tickers'] * 100:.0f}%)\")\n    print(f\"  Neutral:  {summary['neutral']} ({summary['neutral'] / summary['total_tickers'] * 100:.0f}%)\")\n    print(f\"  Bearish:  {summary['bearish']} ({summary['bearish'] / summary['total_tickers'] * 100:.0f}%)\")\n    print()\n    print(f'Confidence Levels:')\n    print(f\"  High:   {summary['high_confidence']}\")\n    print(f\"  Medium: {summary['medium_confidence']}\")\n    print(f\"  Low:    {summary['low_confidence']}\")\n    print('=' * 80 + '\\n')"
    },
    {
      "name": "query_sentiment_rag",
      "line": 526,
      "code": "def query_sentiment_rag(query: str, ticker: Optional[str]=None, top_k: int=5) -> List[Dict]:\n    \"\"\"\n    Retrieve historical sentiment snapshots using the vector store.\n\n    Args:\n        query: Natural language query\n        ticker: Optional ticker symbol to filter results\n        top_k: Number of results to return\n    \"\"\"\n    from src.rag.sentiment_store import SentimentRAGStore\n    store = SentimentRAGStore()\n    return store.query(query=query, ticker=ticker, top_k=top_k)"
    },
    {
      "name": "get_sentiment_history",
      "line": 546,
      "code": "def get_sentiment_history(ticker: str, limit: int=10) -> List[Dict]:\n    \"\"\"\n    Fetch the most recent sentiment snapshots for a ticker from the RAG store.\n\n    Args:\n        ticker: Stock ticker symbol\n        limit: Maximum number of snapshots to return\n    \"\"\"\n    from src.rag.sentiment_store import SentimentRAGStore\n    store = SentimentRAGStore()\n    return store.get_ticker_history(ticker=ticker, limit=limit)"
    }
  ]
}
