{
  "dead_imports": [],
  "commented_blocks": [],
  "empty_functions": [],
  "unused_variables": [],
  "all_functions": [
    {
      "name": "main",
      "line": 137,
      "code": "def main():\n    \"\"\"CLI interface for data collection.\"\"\"\n    parser = argparse.ArgumentParser(description='Collect historical market data')\n    parser.add_argument('--symbols', type=str, default='SPY,QQQ,VOO,NVDA,GOOGL', help='Comma-separated list of symbols (default: SPY,QQQ,VOO,NVDA,GOOGL)')\n    parser.add_argument('--lookback', type=int, default=30, help='Days of historical data to fetch (default: 30)')\n    parser.add_argument('--data-dir', type=str, default='data/historical', help='Directory to store data (default: data/historical)')\n    parser.add_argument('--list', action='store_true', help='List existing data files')\n    parser.add_argument('--load', type=str, help='Load and display historical data for a symbol')\n    args = parser.parse_args()\n    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    collector = DataCollector(data_dir=args.data_dir)\n    if args.list:\n        files = collector.get_existing_files()\n        print(f'\\nFound {len(files)} data files:')\n        for file in files:\n            print(f'  {file}')\n    elif args.load:\n        data = collector.load_historical_data(args.load)\n        print(f'\\nHistorical data for {args.load}:')\n        print(data.head(10))\n        print(f'\\nTotal rows: {len(data)}')\n        print(f'Date range: {data.index.min()} to {data.index.max()}')\n    else:\n        symbols = [s.strip() for s in args.symbols.split(',')]\n        collector.collect_daily_data(symbols, lookback_days=args.lookback)\n        print(f'\\nData collection complete for {len(symbols)} symbols')"
    },
    {
      "name": "__init__",
      "line": 22,
      "code": "def __init__(self, data_dir: str='data/historical'):\n    self.data_dir = Path(data_dir)\n    self.data_dir.mkdir(parents=True, exist_ok=True)\n    self.market_data = get_market_data_provider()\n    logger.info(f'DataCollector initialized: {self.data_dir}')"
    },
    {
      "name": "collect_daily_data",
      "line": 28,
      "code": "def collect_daily_data(self, symbols: List[str], lookback_days: int=30) -> None:\n    \"\"\"\n        Collect and save daily OHLCV data for symbols.\n\n        Args:\n            symbols: List of ticker symbols\n            lookback_days: Days of history to fetch (default: 30)\n        \"\"\"\n    logger.info(f'Collecting data for {len(symbols)} symbols with {lookback_days} days lookback')\n    for symbol in symbols:\n        try:\n            logger.info(f'Fetching data for {symbol}...')\n            data = self.market_data.get_daily_bars(symbol, lookback_days)\n            if data.empty:\n                logger.warning(f'No data returned for {symbol} after fallbacks')\n                continue\n            filepath = self.save_to_csv(symbol, data)\n            logger.info(f'Saved {len(data)} rows for {symbol} to {filepath}')\n        except Exception as e:\n            logger.error(f'Error collecting data for {symbol}: {str(e)}')\n            continue"
    },
    {
      "name": "save_to_csv",
      "line": 57,
      "code": "def save_to_csv(self, symbol: str, data: pd.DataFrame) -> str:\n    \"\"\"\n        Save OHLCV data to CSV file.\n\n        Args:\n            symbol: Ticker symbol\n            data: DataFrame with OHLCV data\n\n        Returns:\n            Path to saved file\n        \"\"\"\n    today = datetime.now().strftime('%Y-%m-%d')\n    filename = f'{symbol}_{today}.csv'\n    filepath = self.data_dir / filename\n    if filepath.exists():\n        logger.info(f'File {filepath} already exists, appending new data')\n        existing_data = pd.read_csv(filepath, index_col=0, parse_dates=True)\n        combined = pd.concat([existing_data, data])\n        combined = combined[~combined.index.duplicated(keep='last')]\n        combined.to_csv(filepath)\n    else:\n        data.to_csv(filepath)\n    return str(filepath)"
    },
    {
      "name": "get_existing_files",
      "line": 88,
      "code": "def get_existing_files(self, symbol: Optional[str]=None) -> List[Path]:\n    \"\"\"\n        List existing CSV files in data directory.\n\n        Args:\n            symbol: Optional symbol to filter by\n\n        Returns:\n            List of Path objects for matching files\n        \"\"\"\n    if symbol:\n        pattern = f'{symbol}_*.csv'\n    else:\n        pattern = '*.csv'\n    files = list(self.data_dir.glob(pattern))\n    return sorted(files)"
    },
    {
      "name": "load_historical_data",
      "line": 106,
      "code": "def load_historical_data(self, symbol: str) -> pd.DataFrame:\n    \"\"\"\n        Load all historical data for a symbol from CSV files.\n\n        Args:\n            symbol: Ticker symbol\n\n        Returns:\n            Combined DataFrame with all historical data\n        \"\"\"\n    files = self.get_existing_files(symbol)\n    if not files:\n        logger.warning(f'No historical data found for {symbol}')\n        return pd.DataFrame()\n    dataframes = []\n    for file in files:\n        df = pd.read_csv(file, index_col=0, parse_dates=True)\n        dataframes.append(df)\n    combined = pd.concat(dataframes)\n    combined = combined[~combined.index.duplicated(keep='last')]\n    combined.sort_index(inplace=True)\n    logger.info(f'Loaded {len(combined)} rows for {symbol} from {len(files)} files')\n    return combined"
    }
  ]
}
