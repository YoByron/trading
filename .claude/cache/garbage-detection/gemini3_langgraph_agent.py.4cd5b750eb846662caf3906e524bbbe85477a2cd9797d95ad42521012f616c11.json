{
  "dead_imports": [
    {
      "line": 345,
      "module": "PIL.Image",
      "statement": "import PIL.Image"
    }
  ],
  "commented_blocks": [],
  "empty_functions": [],
  "unused_variables": [
    {
      "line": 33,
      "variable": "AIMessage"
    }
  ],
  "all_functions": [
    {
      "name": "create_trading_agent",
      "line": 376,
      "code": "def create_trading_agent(model: str='gemini-3.0-pro', thinking_level: str='medium') -> Gemini3LangGraphAgent:\n    \"\"\"\n    Factory function to create Gemini 3 trading agent.\n    \n    Args:\n        model: Gemini model name\n        thinking_level: Default reasoning depth\n        \n    Returns:\n        Configured Gemini3LangGraphAgent instance\n    \"\"\"\n    return Gemini3LangGraphAgent(model=model, default_thinking_level=thinking_level)"
    },
    {
      "name": "__init__",
      "line": 61,
      "code": "def __init__(self, model: str='gemini-3.0-pro', default_thinking_level: str='medium', temperature: float=0.7):\n    \"\"\"\n        Initialize Gemini 3 LangGraph agent.\n        \n        Args:\n            model: Gemini model name\n            default_thinking_level: Default reasoning depth\n            temperature: Model temperature\n        \"\"\"\n    self.model_name = model\n    self.default_thinking_level = default_thinking_level\n    self.temperature = temperature\n    api_key = os.getenv('GOOGLE_API_KEY')\n    if not api_key:\n        logger.warning('GOOGLE_API_KEY not found')\n        self.llm = None\n        self.workflow = None\n    elif not genai or not ChatGoogleGenerativeAI:\n        logger.warning('Gemini dependencies not installed')\n        self.llm = None\n        self.workflow = None\n    else:\n        try:\n            genai.configure(api_key=api_key)\n            self.llm = ChatGoogleGenerativeAI(model=model, temperature=temperature, google_api_key=api_key)\n            if StateGraph:\n                self.workflow = self._build_workflow()\n            else:\n                logger.warning('LangGraph not available - workflow disabled')\n                self.workflow = None\n        except Exception as e:\n            logger.error(f'Failed to initialize Gemini 3: {e}')\n            self.llm = None\n            self.workflow = None\n    logger.info(f'Initialized Gemini3LangGraphAgent with {model}')"
    },
    {
      "name": "_build_workflow",
      "line": 112,
      "code": "def _build_workflow(self):\n    \"\"\"Build LangGraph workflow for multi-agent system.\"\"\"\n    if not StateGraph:\n        return None\n    workflow = StateGraph(AgentState)\n    workflow.add_node('research', self._research_agent)\n    workflow.add_node('analyze', self._analysis_agent)\n    workflow.add_node('decide', self._decision_agent)\n    workflow.set_entry_point('research')\n    workflow.add_edge('research', 'analyze')\n    workflow.add_edge('analyze', 'decide')\n    workflow.add_edge('decide', END)\n    return workflow.compile()"
    },
    {
      "name": "_research_agent",
      "line": 132,
      "code": "def _research_agent(self, state: AgentState) -> AgentState:\n    \"\"\"Research agent - gathers market data and context.\"\"\"\n    logger.info('Research agent: Gathering market data')\n    thinking_level = 'high'\n    prompt = f\"You are a market research agent. Analyze the following market data:\\n\\n{json.dumps(state.get('market_data', {}), indent=2)}\\n\\nProvide:\\n1. Key market trends\\n2. Risk factors\\n3. Opportunities\\n4. Market regime (bullish/bearish/neutral)\\n\\nUse thinking_level={thinking_level} for deep analysis.\\n\"\n    if self.llm:\n        messages = state.get('messages', [])\n        messages.append(HumanMessage(content=prompt))\n        response = self.llm.invoke(messages)\n        thought_sig = getattr(response, 'thought_signature', None)\n        if thought_sig:\n            state['thought_signatures'].append(thought_sig)\n        state['messages'].append(response)\n        state['analysis']['research'] = response.content\n    return state"
    },
    {
      "name": "_analysis_agent",
      "line": 168,
      "code": "def _analysis_agent(self, state: AgentState) -> AgentState:\n    \"\"\"Analysis agent - performs technical and fundamental analysis.\"\"\"\n    logger.info('Analysis agent: Performing analysis')\n    thinking_level = 'medium'\n    prompt = f\"You are a trading analysis agent. Based on the research:\\n\\n{state.get('analysis', {}).get('research', '')}\\n\\nPerform technical and fundamental analysis:\\n1. Technical indicators (MACD, RSI, Volume)\\n2. Entry/exit signals\\n3. Risk assessment\\n4. Position sizing recommendations\\n\\nUse thinking_level={thinking_level} for balanced analysis.\\n\"\n    if self.llm:\n        messages = state.get('messages', [])\n        messages.append(HumanMessage(content=prompt))\n        response = self.llm.invoke(messages)\n        thought_sig = getattr(response, 'thought_signature', None)\n        if thought_sig:\n            state['thought_signatures'].append(thought_sig)\n        state['messages'].append(response)\n        state['analysis']['technical'] = response.content\n    return state"
    },
    {
      "name": "_decision_agent",
      "line": 203,
      "code": "def _decision_agent(self, state: AgentState) -> AgentState:\n    \"\"\"Decision agent - makes final trading decision.\"\"\"\n    logger.info('Decision agent: Making trading decision')\n    thinking_level = 'low'\n    prompt = f\"You are a trading decision agent. Based on research and analysis:\\n\\nResearch: {state.get('analysis', {}).get('research', '')}\\nAnalysis: {state.get('analysis', {}).get('technical', '')}\\n\\nMake a final trading decision:\\n1. Action: BUY/SELL/HOLD\\n2. Symbol: Which asset\\n3. Position size: How much\\n4. Confidence: 0-1\\n5. Reasoning: Why\\n\\nUse thinking_level={thinking_level} for quick decision.\\nFormat as JSON.\\n\"\n    if self.llm:\n        messages = state.get('messages', [])\n        messages.append(HumanMessage(content=prompt))\n        response = self.llm.invoke(messages)\n        thought_sig = getattr(response, 'thought_signature', None)\n        if thought_sig:\n            state['thought_signatures'].append(thought_sig)\n        state['messages'].append(response)\n        try:\n            decision_text = response.content\n            if '{' in decision_text:\n                json_start = decision_text.find('{')\n                json_end = decision_text.rfind('}') + 1\n                decision_json = json.loads(decision_text[json_start:json_end])\n                state['decision'] = decision_json\n            else:\n                state['decision'] = {'action': 'HOLD', 'reasoning': decision_text}\n        except Exception as e:\n            logger.error(f'Failed to parse decision: {e}')\n            state['decision'] = {'action': 'HOLD', 'error': str(e)}\n    return state"
    },
    {
      "name": "evaluate",
      "line": 255,
      "code": "def evaluate(self, market_data: Dict[str, Any], thinking_level: Optional[str]=None) -> Dict[str, Any]:\n    \"\"\"\n        Evaluate trading opportunity using multi-agent system.\n        \n        Args:\n            market_data: Market data dictionary\n            thinking_level: Reasoning depth (low/medium/high)\n            \n        Returns:\n            Trading decision with reasoning\n        \"\"\"\n    if not self.llm:\n        return {'error': 'Gemini API not configured'}\n    thinking_level = thinking_level or self.default_thinking_level\n    initial_state: AgentState = {'messages': [SystemMessage(content=f'You are a sophisticated trading AI system. Use thinking_level={thinking_level} for reasoning depth.')], 'market_data': market_data, 'analysis': {}, 'decision': None, 'thought_signatures': [], 'thinking_level': thinking_level}\n    if not self.workflow:\n        if self.llm:\n            try:\n                response = self.llm.invoke(initial_state['messages'])\n                return {'decision': {'action': 'HOLD', 'reasoning': response.content}, 'analysis': {}, 'thought_signatures': [], 'thinking_level': thinking_level}\n            except Exception as e:\n                logger.error(f'Direct LLM call failed: {e}')\n        return {'error': 'Workflow not available'}\n    try:\n        final_state = self.workflow.invoke(initial_state)\n        return {'decision': final_state.get('decision'), 'analysis': final_state.get('analysis'), 'thought_signatures': final_state.get('thought_signatures', []), 'thinking_level': thinking_level, 'messages': [{'role': msg.type, 'content': msg.content} for msg in final_state.get('messages', []) if hasattr(msg, 'content')]}\n    except Exception as e:\n        logger.error(f'Workflow execution error: {e}')\n        return {'error': str(e), 'decision': {'action': 'HOLD', 'reasoning': 'System error'}}"
    },
    {
      "name": "analyze_chart",
      "line": 324,
      "code": "def analyze_chart(self, chart_image_path: str, symbol: str, thinking_level: str='high') -> Dict[str, Any]:\n    \"\"\"\n        Analyze chart image using multimodal capabilities.\n        \n        Args:\n            chart_image_path: Path to chart image\n            symbol: Stock symbol\n            thinking_level: Reasoning depth\n            \n        Returns:\n            Chart analysis results\n        \"\"\"\n    if not self.llm:\n        return {'error': 'Gemini API not configured'}\n    try:\n        import PIL.Image\n        image = PIL.Image.open(chart_image_path)\n        prompt = f'Analyze this {symbol} price chart:\\n\\n1. Identify trend (uptrend/downtrend/sideways)\\n2. Key support/resistance levels\\n3. Chart patterns (head & shoulders, triangles, etc.)\\n4. Trading signals\\n5. Risk assessment\\n\\nUse thinking_level={thinking_level} for detailed analysis.\\n'\n        model = genai.GenerativeModel(self.model_name)\n        response = model.generate_content([prompt, image])\n        return {'symbol': symbol, 'analysis': response.text, 'thinking_level': thinking_level, 'timestamp': datetime.now().isoformat()}\n    except Exception as e:\n        logger.error(f'Chart analysis error: {e}')\n        return {'error': str(e)}"
    }
  ]
}
