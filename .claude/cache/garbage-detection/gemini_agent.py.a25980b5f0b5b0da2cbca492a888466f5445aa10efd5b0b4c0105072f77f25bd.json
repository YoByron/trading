{
  "dead_imports": [],
  "commented_blocks": [],
  "empty_functions": [],
  "unused_variables": [],
  "all_functions": [
    {
      "name": "__init__",
      "line": 32,
      "code": "def __init__(self, name: str, role: str, model: str='gemini-3-pro-preview', default_thinking_level: str='medium'):\n    \"\"\"\n        Initialize Gemini 3 agent.\n        \n        Args:\n            name: Agent name\n            role: Agent role/responsibility\n            model: Gemini model to use\n            default_thinking_level: Default reasoning depth (low/medium/high)\n        \"\"\"\n    self.name = name\n    self.role = role\n    self.model = model\n    self.default_thinking_level = default_thinking_level\n    api_key = os.getenv('GOOGLE_API_KEY')\n    if not api_key:\n        logger.warning('GOOGLE_API_KEY not found, Gemini agent will not function')\n    else:\n        genai.configure(api_key=api_key)\n    self.client = genai.GenerativeModel(model)\n    self.memory: List[Dict[str, Any]] = []\n    self.decision_log: List[Dict[str, Any]] = []\n    self.thought_signatures: List[str] = []\n    logger.info(f'Initialized {name} with Gemini 3 ({model})')"
    },
    {
      "name": "reason",
      "line": 71,
      "code": "@with_retry(max_attempts=3, backoff=2.0)\ndef reason(self, prompt: str, thinking_level: Optional[str]=None, tools: Optional[List[Dict]]=None, context: Optional[List[Dict]]=None) -> Dict[str, Any]:\n    \"\"\"\n        Use Gemini 3 reasoning to make decisions.\n        \n        Args:\n            prompt: The reasoning prompt\n            thinking_level: Reasoning depth (low/medium/high), defaults to agent's default\n            tools: Optional tool definitions for function calling\n            context: Optional conversation context with thought signatures\n            \n        Returns:\n            Response with reasoning, decision, and thought signature\n        \"\"\"\n    thinking_level = thinking_level or self.default_thinking_level\n    try:\n        generation_config = {'temperature': 0.7, 'top_p': 0.95, 'top_k': 40, 'max_output_tokens': 4096}\n        if hasattr(genai.types, 'ThinkingLevel'):\n            generation_config['thinking_level'] = thinking_level\n        messages = []\n        if context:\n            messages.extend(context)\n        messages.append({'role': 'user', 'parts': [prompt]})\n        if tools:\n            response = self.client.generate_content(messages, generation_config=generation_config, tools=tools)\n        else:\n            response = self.client.generate_content(messages, generation_config=generation_config)\n        thought_signature = None\n        if hasattr(response, 'thought_signature'):\n            thought_signature = response.thought_signature\n            self.thought_signatures.append(thought_signature)\n        result = {'reasoning': response.text if hasattr(response, 'text') else '', 'decision': '', 'confidence': 0.0, 'thought_signature': thought_signature, 'tool_calls': [], 'thinking_level': thinking_level}\n        if hasattr(response, 'function_calls'):\n            for call in response.function_calls:\n                result['tool_calls'].append({'name': call.name, 'args': dict(call.args)})\n        return result\n    except Exception as e:\n        logger.error(f'{self.name} Gemini reasoning error: {e}')\n        return {'reasoning': f'Error: {str(e)}', 'decision': 'NO_ACTION', 'confidence': 0.0, 'thought_signature': None, 'tool_calls': [], 'thinking_level': thinking_level}"
    },
    {
      "name": "analyze_with_context",
      "line": 163,
      "code": "def analyze_with_context(self, data: Dict[str, Any], thinking_level: str='high') -> Dict[str, Any]:\n    \"\"\"\n        Analyze data with full context preservation.\n        \n        Args:\n            data: Input data for analysis\n            thinking_level: Reasoning depth for this analysis\n            \n        Returns:\n            Analysis results with preserved thought signatures\n        \"\"\"\n    context = []\n    for i, sig in enumerate(self.thought_signatures[-5:]):\n        context.append({'role': 'model', 'parts': [f'[Thought Signature {i}]'], 'thought_signature': sig})\n    prompt = self._build_analysis_prompt(data)\n    result = self.reason(prompt=prompt, thinking_level=thinking_level, context=context)\n    self.log_decision(result)\n    return result"
    },
    {
      "name": "_build_analysis_prompt",
      "line": 202,
      "code": "def _build_analysis_prompt(self, data: Dict[str, Any]) -> str:\n    \"\"\"Build analysis prompt from data.\"\"\"\n    return f'You are {self.name}, responsible for: {self.role}\\n\\nAnalyze the following data and provide your recommendation:\\n\\n{json.dumps(data, indent=2)}\\n\\nProvide:\\n1. Your reasoning\\n2. Recommended action\\n3. Confidence level (0-1)\\n4. Key factors influencing your decision\\n'"
    },
    {
      "name": "log_decision",
      "line": 217,
      "code": "def log_decision(self, decision: Dict[str, Any]) -> None:\n    \"\"\"Log a decision for audit trail.\"\"\"\n    entry = {'timestamp': datetime.now().isoformat(), 'agent': self.name, 'decision': decision, 'thought_signature': decision.get('thought_signature')}\n    self.decision_log.append(entry)\n    logger.info(f'{self.name} decision logged')"
    },
    {
      "name": "get_memory_context",
      "line": 228,
      "code": "def get_memory_context(self, limit: int=10) -> str:\n    \"\"\"Get recent memory context for reasoning.\"\"\"\n    recent_memories = self.memory[-limit:]\n    if not recent_memories:\n        return 'No previous experience.'\n    context = 'Recent experience:\\n'\n    for mem in recent_memories:\n        outcome = mem.get('outcome', {})\n        context += f\"- {mem['timestamp']}: {outcome.get('result', 'N/A')}\\n\"\n    return context"
    },
    {
      "name": "health_check",
      "line": 241,
      "code": "def health_check(self) -> bool:\n    \"\"\"Run health check on agent.\"\"\"\n    return health_check(threshold=5, window_seconds=3600)"
    }
  ]
}
