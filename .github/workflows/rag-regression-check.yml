name: RAG Regression Check

on:
  pull_request:
    types: [opened, synchronize, reopened]

permissions:
  contents: read
  pull-requests: write

jobs:
  rag-check:
    runs-on: ubuntu-22.04
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install numpy sentence-transformers

      - name: Get changed files
        id: changed
        run: |
          FILES=$(git diff --name-only origin/main...HEAD | tr '\n' ' ')
          echo "files=$FILES" >> $GITHUB_OUTPUT

      - name: Run RAG regression check
        id: rag
        run: |
          python << 'EOF'
          import json
          import sys
          from pathlib import Path

          # Simple keyword extraction
          changed_files = "${{ steps.changed.outputs.files }}".split()
          keywords = set()
          for f in changed_files:
              parts = Path(f).stem.replace("_", " ").split()
              keywords.update(parts)

          # Load lessons from markdown files
          lessons_dir = Path("rag_knowledge/lessons_learned")
          warnings = []
          if lessons_dir.exists():
              for lesson_file in lessons_dir.glob("*.md"):
                  content = lesson_file.read_text().lower()
                  # Check if any keyword matches
                  matches = [k for k in keywords if k.lower() in content]
                  if len(matches) >= 2:  # At least 2 keyword matches
                      # Extract severity
                      severity = "medium"
                      if "severity: high" in content or "severity**: high" in content:
                          severity = "high"
                      elif "severity: critical" in content:
                          severity = "critical"

                      # Extract title (first # header)
                      title = lesson_file.stem.replace("_", " ")
                      for line in content.split("\n"):
                          if line.startswith("# "):
                              title = line[2:].strip()
                              break

                      warnings.append({
                          "file": lesson_file.name,
                          "title": title[:80],
                          "severity": severity,
                          "matches": matches[:5]
                      })

          # Output
          if warnings:
              print("::warning::Found relevant lessons from past mistakes!")
              for w in warnings[:5]:
                  print(f"::warning file={w['file']}::[{w['severity'].upper()}] {w['title']}")

          # Write summary
          with open("rag_summary.json", "w") as f:
              json.dump({"warnings": warnings, "keywords": list(keywords)}, f)

          # Exit with warning but don't fail
          sys.exit(0)
          EOF

      - name: Comment on PR
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let summary = {warnings: [], keywords: []};
            try {
              summary = JSON.parse(fs.readFileSync('rag_summary.json', 'utf8'));
            } catch (e) {}

            if (summary.warnings.length > 0) {
              const warningList = summary.warnings.map(w =>
                `- **[${w.severity.toUpperCase()}]** ${w.title} (matches: ${w.matches.join(', ')})`
              ).join('\n');

              const body = `## ðŸ“š RAG Lessons Check

              Found ${summary.warnings.length} relevant lesson(s) from past mistakes:

              ${warningList}

              **Please review these lessons before merging.** They may contain important context about similar issues we've encountered before.

              <details>
              <summary>Keywords analyzed</summary>

              \`${summary.keywords.join(', ')}\`
              </details>
              `;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }
