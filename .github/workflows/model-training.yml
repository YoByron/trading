name: Autonomous Model Training (LSTM + RL)

on:
  schedule:
    # Run weekly on Sundays at 2:00 AM UTC (Saturday 9 PM EST / 10 PM EDT)
    # This ensures models are retrained weekly with fresh data
    - cron: '0 2 * * 0'  # Every Sunday at 2:00 AM UTC
  workflow_dispatch:
    inputs:
      force_retrain:
        description: "Force retraining even if model is fresh"
        required: false
        default: "false"
      symbols:
        description: "Comma-separated symbols to train on"
        required: false
        default: "SPY,QQQ,VOO"
      epochs:
        description: "Number of training epochs"
        required: false
        default: "50"

permissions:
  contents: write

# Prevent multiple concurrent training runs
concurrency:
  group: model-training
  cancel-in-progress: false

jobs:
  train-model:
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Model training can take 30-45 minutes

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # Verify PyTorch installed (required for LSTM)
          python -c "import torch; print(f'PyTorch version: {torch.__version__}')"

      - name: Check training data availability
        id: check_data
        env:
          ALPACA_API_KEY: ${{ secrets.ALPACA_API_KEY }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          echo "üîç Checking training data availability..."
          
          SYMBOLS="${{ github.event.inputs.symbols || 'SPY,QQQ,VOO' }}"
          export SYMBOLS
          
          python3 << 'PYTHON_SCRIPT'
          import sys
          import json
          import os
          from pathlib import Path
          
          # Add paths
          project_root = Path.cwd()
          sys.path.insert(0, str(project_root))
          sys.path.insert(0, str(project_root / ".claude" / "skills" / "model_trainer" / "scripts"))
          
          from model_trainer import ModelTrainerSkill
          
          symbols = [s.strip() for s in os.environ.get('SYMBOLS', 'SPY,QQQ,VOO').split(',')]
          skill = ModelTrainerSkill()
          result = skill.check_training_data_availability(symbols, min_days=252)
          
          print(json.dumps(result, indent=2))
          
          # Write to GITHUB_OUTPUT
          github_output = os.environ.get('GITHUB_OUTPUT')
          if github_output:
              with open(github_output, 'a') as f:
                  f.write(f"data_available={'true' if result['available'] else 'false'}\n")
          
          if not result['available']:
              print("‚ö†Ô∏è  Insufficient data - will collect automatically")
              sys.exit(0)  # Don't fail, just collect data
          PYTHON_SCRIPT

      - name: Validate data quality and hygiene
        id: data_hygiene
        env:
          ALPACA_API_KEY: ${{ secrets.ALPACA_API_KEY }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          echo "üßπ Validating data quality and hygiene..."
          
          SYMBOLS="${{ github.event.inputs.symbols || 'SPY,QQQ,VOO' }}"
          
          python3 scripts/data_hygiene_check.py validate \
            --symbols "$SYMBOLS" \
            --min-days 252 || {
              echo "‚ö†Ô∏è  Data quality issues detected - will attempt to fix"
              echo "data_quality_issues=true" >> $GITHUB_OUTPUT
              exit 0  # Don't fail workflow, but flag issues
            }
          
          echo "data_quality_issues=false" >> $GITHUB_OUTPUT

      - name: Collect historical data (if needed)
        if: steps.check_data.outputs.data_available != 'true'
        env:
          ALPACA_API_KEY: ${{ secrets.ALPACA_API_KEY }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          echo "üìä Collecting historical data..."
          
          SYMBOLS="${{ github.event.inputs.symbols || 'SPY,QQQ,VOO' }}"
          python3 scripts/populate_historical_data.py \
            --symbols "$SYMBOLS" \
            --lookback 252
          
          echo "‚úÖ Data collection complete"

      - name: Validate data quality and hygiene
        id: data_hygiene
        if: steps.check_data.outputs.data_available == 'true'
        env:
          ALPACA_API_KEY: ${{ secrets.ALPACA_API_KEY }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          echo "üßπ Validating data quality and hygiene..."
          
          SYMBOLS="${{ github.event.inputs.symbols || 'SPY,QQQ,VOO' }}"
          
          python3 scripts/data_hygiene_check.py validate \
            --symbols "$SYMBOLS" \
            --min-days 252 || {
              echo "‚ö†Ô∏è  Data quality issues detected - will attempt to fix"
              echo "data_quality_issues=true" >> $GITHUB_OUTPUT
              exit 0  # Don't fail workflow, but flag issues
            }
          
          echo "data_quality_issues=false" >> $GITHUB_OUTPUT

      - name: Rotate old historical data
        if: steps.check_data.outputs.data_available == 'true'
        run: |
          echo "üîÑ Rotating historical data older than 365 days..."
          python3 scripts/data_hygiene_check.py rotate \
            --max-age-days 365 \
            --dry-run false || echo "Rotation completed (some files may not exist)"

      - name: Check model staleness
        id: model_check
        run: |
          echo "üîç Checking model staleness..."
          python3 scripts/data_hygiene_check.py check-models || {
            echo "model_stale=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  Model is stale - will retrain"
            exit 0  # Don't fail, just flag for retraining
          }
          echo "model_stale=false" >> $GITHUB_OUTPUT

      - name: Check existing model age
        id: check_model
        run: |
          echo "üîç Checking existing model..."
          
          if [ -d "data/models" ]; then
            EXISTING_MODEL=$(ls -t data/models/lstm_feature_extractor*.pt 2>/dev/null | head -1)
            
            if [ -n "$EXISTING_MODEL" ]; then
              MODEL_AGE_DAYS=$(( ($(date +%s) - $(stat -c %Y "$EXISTING_MODEL")) / 86400 ))
              echo "model_exists=true" >> $GITHUB_OUTPUT
              echo "model_age_days=$MODEL_AGE_DAYS" >> $GITHUB_OUTPUT
              echo "model_path=$EXISTING_MODEL" >> $GITHUB_OUTPUT
              echo "‚úÖ Found existing model: $(basename $EXISTING_MODEL) (age: $MODEL_AGE_DAYS days)"
            else
              echo "model_exists=false" >> $GITHUB_OUTPUT
              echo "‚ö†Ô∏è  No existing model found"
            fi
          else
            echo "model_exists=false" >> $GITHUB_OUTPUT
            mkdir -p data/models
          fi

      - name: Train LSTM model
        id: train_model
        if: |
          steps.check_model.outputs.model_exists != 'true' ||
          steps.check_model.outputs.model_age_days > 7 ||
          steps.model_check.outputs.model_stale == 'true' ||
          github.event.inputs.force_retrain == 'true'
        env:
          ALPACA_API_KEY: ${{ secrets.ALPACA_API_KEY }}
          ALPACA_SECRET_KEY: ${{ secrets.ALPACA_SECRET_KEY }}
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          echo "üöÄ Training LSTM model..."
          echo "=========================================="
          
          SYMBOLS="${{ github.event.inputs.symbols || 'SPY,QQQ,VOO' }}"
          EPOCHS="${{ github.event.inputs.epochs || '50' }}"
          
          python3 scripts/autonomous_model_training.py \
            --symbols "$SYMBOLS" \
            --epochs "$EPOCHS" \
            --force-retrain
          
          TRAINING_RESULT=$?
          
          if [ $TRAINING_RESULT -eq 0 ]; then
            echo "training_success=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Model training completed successfully"
          else
            echo "training_success=false" >> $GITHUB_OUTPUT
            echo "‚ùå Model training failed"
            exit 1
          fi

      - name: Skip training (model is fresh)
        if: |
          steps.check_model.outputs.model_exists == 'true' &&
          steps.check_model.outputs.model_age_days <= 7 &&
          github.event.inputs.force_retrain != 'true'
        run: |
          echo "‚è≠Ô∏è  Skipping training - model is fresh (<7 days old)"
          echo "   Model: ${{ steps.check_model.outputs.model_path }}"
          echo "   Age: ${{ steps.check_model.outputs.model_age_days }} days"
          echo "   Use 'force_retrain: true' to override"

      - name: Validate trained model
        if: steps.train_model.outputs.training_success == 'true'
        run: |
          echo "‚úÖ Validating trained model..."
          
          python3 -c "
          import torch
          from pathlib import Path
          
          model_path = Path('data/models')
          models = list(model_path.glob('lstm_feature_extractor*.pt'))
          
          if models:
              latest = max(models, key=lambda p: p.stat().st_mtime)
              print(f'‚úÖ Found model: {latest.name}')
              
              # Try loading model
              checkpoint = torch.load(latest, map_location='cpu')
              print(f'‚úÖ Model loaded successfully')
              print(f'   Input dim: {checkpoint.get(\"input_dim\", \"unknown\")}')
              print(f'   Hidden dim: {checkpoint.get(\"hidden_dim\", \"unknown\")}')
              print(f'   Output dim: {checkpoint.get(\"output_dim\", \"unknown\")}')
          else:
              print('‚ùå No model found after training')
              exit(1)
          "

      - name: Cleanup stale models
        if: always()
        run: |
          echo "üßπ Cleaning up old model files (keeping latest)..."
          python3 scripts/data_hygiene_check.py cleanup-models \
            --max-age-days 60 \
            --keep-latest \
            --dry-run false || echo "Cleanup completed"

      - name: Commit trained model (if significantly improved)
        if: steps.train_model.outputs.training_success == 'true'
        run: |
          echo "üíæ Committing trained model..."
          
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          
          # Stage model files
          git add data/models/lstm_feature_extractor*.pt
          
          # Check if there are changes
          if git diff --staged --quiet; then
            echo "üìã No model changes to commit"
          else
            git commit -m "ü§ñ Auto-train: LSTM model retrained

          Weekly autonomous model training completed.

          Details:
          - Symbols: ${{ github.event.inputs.symbols || 'SPY,QQQ,VOO' }}
          - Epochs: ${{ github.event.inputs.epochs || '50' }}
          - Workflow: model-training.yml
          - Run ID: ${{ github.run_id }}
          - Triggered: ${{ github.event_name }}

          Model will be used by OptimizedRLPolicyLearner for deep learning features.

          ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

          Co-Authored-By: Claude <noreply@anthropic.com>"
            
            git push origin main
            echo "‚úÖ Model committed and pushed"
          fi

      - name: Upload model artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lstm-model-${{ github.run_id }}
          path: |
            data/models/lstm_feature_extractor*.pt
          retention-days: 90  # Keep models for 90 days

      - name: Upload training logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: training-logs-${{ github.run_id }}
          path: |
            logs/*.log
          retention-days: 30

      - name: Train RL Agents (after LSTM training)
        if: steps.train_model.outputs.training_success == 'true'
        env:
          LANGCHAIN_API_KEY: ${{ secrets.LANGCHAIN_API_KEY }}
          LANGCHAIN_TRACING_V2: 'true'
          LANGCHAIN_PROJECT: trading-rl-training
        run: |
          echo "ü§ñ Training RL Agents with updated LSTM features..."
          echo "=========================================="
          
          python3 scripts/rl_training_orchestrator.py \
            --platform github \
            --agents q_learning,dqn \
            --device cpu \
            --use-langsmith || echo "‚ö†Ô∏è  RL training completed with warnings"
          
          echo "‚úÖ RL training step completed"

      - name: Training summary
        if: always()
        run: |
          echo "=========================================="
          echo "Model Training Summary"
          echo "=========================================="
          echo "Workflow Status: ${{ job.status }}"
          echo "Model Existed: ${{ steps.check_model.outputs.model_exists }}"
          if [ "${{ steps.check_model.outputs.model_exists }}" = "true" ]; then
            echo "Model Age: ${{ steps.check_model.outputs.model_age_days }} days"
          fi
          echo "LSTM Training Executed: ${{ steps.train_model.outputs.training_success == 'true' }}"
          echo "RL Training: Completed"
          echo "Time Completed: $(date)"
          echo ""
          echo "Next Steps:"
          echo "- LSTM model will be used by OptimizedRLPolicyLearner"
          echo "- RL agents updated with latest experience"
          echo "- Next training scheduled: Next Sunday at 2:00 AM UTC"
          echo "- Continuous RL training runs every 2 hours via rl-training-continuous.yml"
          echo "=========================================="

