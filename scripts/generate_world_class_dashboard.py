#!/usr/bin/env python3
"""
Generate World-Class Trading Dashboard

Implements elite-level dashboard comparable to:
- Two Sigma internal dashboards
- QuantConnect premium analytics
- HFT trading desks
- Hedge fund risk consoles

Features:
- Predictive analytics (Monte Carlo forecasting)
- Comprehensive risk metrics
- Performance attribution by strategy/asset
- AI-generated insights with trade analysis
- Strategy-level breakdown
- Rich visualizations (ASCII charts)
- Real-time monitoring status
- Actionable risk alerts
"""

import json
import logging
import os
import sys
from collections import defaultdict
from datetime import date, datetime
from pathlib import Path
from typing import Any

import numpy as np

logger = logging.getLogger(__name__)

# Add parent directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))

try:
    from src.analytics.ai_insights import AIInsightGenerator
    from src.analytics.world_class_analytics import WorldClassAnalytics
except ImportError:
    print("‚ö†Ô∏è  Analytics modules not available - using basic metrics")
    WorldClassAnalytics = None
    AIInsightGenerator = None

try:
    from src.utils.tax_optimization import TaxOptimizer
except ImportError:
    print("‚ö†Ô∏è  Tax optimization module not available")
    TaxOptimizer = None

DATA_DIR = Path("data")
RAG_DIR = DATA_DIR / "rag"

# Statistical significance thresholds (investor-grade)
STAT_THRESHOLDS = {
    "sharpe_sortino": 30,  # Need 30+ closed trades for Sharpe/Sortino
    "win_rate": 10,  # Need 10+ closed trades for meaningful win rate
    "profit_factor": 20,  # Need 20+ closed trades for profit factor
    "per_strategy": 10,  # Need 10+ trades per strategy
    "cohort_analysis": 20,  # Need 20+ trades per cohort
    "alpha": 50,  # Need 50+ closed trades for alpha
    "capital_efficiency": 20,  # Need 20+ closed trades
    "monte_carlo": 10,  # Need 10+ returns for Monte Carlo
    "distribution": 5,  # Need 5+ days for distribution analysis
}

# Phase 1 investor view: only show these sections when data thresholds met
INVESTOR_VIEW_GATES = {
    "show_sharpe_sortino": lambda trades: len([t for t in trades if t.get("pl") is not None]) >= 30,
    "show_profit_factor": lambda trades: len([t for t in trades if t.get("pl") is not None]) >= 20,
    "show_per_strategy": lambda trades, strategy: len(
        [t for t in trades if t.get("tier") == strategy and t.get("pl") is not None]
    )
    >= 10,
    "show_alpha": lambda trades: len([t for t in trades if t.get("pl") is not None]) >= 50,
}


def load_json_file(filepath: Path) -> dict:
    """Load JSON file, return empty dict if not found."""
    if filepath.exists():
        try:
            with open(filepath) as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def get_recent_trades(days: int = 7) -> list[dict]:
    """Get trades from the last N days for dashboard display."""
    from datetime import timedelta

    recent_trades = []
    today = date.today()

    for i in range(days):
        trade_date = today - timedelta(days=i)
        trades_file = DATA_DIR / f"trades_{trade_date.isoformat()}.json"
        if trades_file.exists():
            try:
                with open(trades_file) as f:
                    day_trades = json.load(f)
                    if isinstance(day_trades, list):
                        for trade in day_trades:
                            trade["trade_date"] = trade_date.isoformat()
                            recent_trades.append(trade)
            except Exception:
                continue

    # Sort by timestamp (most recent first)
    recent_trades.sort(
        key=lambda x: x.get("timestamp", x.get("trade_date", "")), reverse=True
    )
    return recent_trades


def get_rag_knowledge_stats() -> dict[str, Any]:
    """Get RAG Knowledge Base statistics for dashboard."""
    import sqlite3

    stats = {
        "sentiment_rag": {"count": 0, "status": "‚ö†Ô∏è Empty", "last_update": "Never"},
        "berkshire": {"count": 0, "parsed": 0, "year_range": "N/A", "size_mb": 0.0},
        "bogleheads": {"insights": 0, "files": 0, "status": "Pending"},
        "youtube": {"transcripts": 0, "size_kb": 0},
        "reddit": {"count": 0},
        "news": {"count": 0},
    }

    # Sentiment RAG database
    db_path = RAG_DIR / "sentiment_rag.db"
    if db_path.exists():
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*), MAX(snapshot_date) FROM sentiment_documents")
            row = cursor.fetchone()
            conn.close()
            if row:
                stats["sentiment_rag"]["count"] = row[0] or 0
                stats["sentiment_rag"]["last_update"] = row[1] or "Never"
                stats["sentiment_rag"]["status"] = (
                    "‚úÖ Active" if row[0] and row[0] > 0 else "‚ö†Ô∏è Empty"
                )
        except Exception:
            pass

    # Berkshire Letters
    raw_dir = RAG_DIR / "berkshire_letters" / "raw"
    parsed_dir = RAG_DIR / "berkshire_letters" / "parsed"
    if raw_dir.exists():
        raw_files = list(raw_dir.glob("*.pdf"))
        parsed_files = list(parsed_dir.glob("*.txt")) if parsed_dir.exists() else []
        years = sorted([int(f.stem) for f in raw_files if f.stem.isdigit()], reverse=True)
        total_size = sum(f.stat().st_size for f in raw_files) / (1024 * 1024)
        stats["berkshire"]["count"] = len(raw_files)
        stats["berkshire"]["parsed"] = len(parsed_files)
        stats["berkshire"]["year_range"] = f"{min(years)}-{max(years)}" if years else "N/A"
        stats["berkshire"]["size_mb"] = round(total_size, 2)

    # Bogleheads Forum
    bogleheads_dir = RAG_DIR / "bogleheads"
    if bogleheads_dir.exists():
        files = list(bogleheads_dir.glob("*.json"))
        total_insights = 0
        for f in files:
            try:
                with open(f) as fp:
                    data = json.load(fp)
                    if isinstance(data, list):
                        total_insights += len(data)
            except Exception:
                pass
        stats["bogleheads"]["files"] = len(files)
        stats["bogleheads"]["insights"] = total_insights
        stats["bogleheads"]["status"] = "Active" if total_insights > 0 else "Pending"

    # YouTube Transcripts
    cache_dir = DATA_DIR / "youtube_cache"
    if cache_dir.exists():
        transcripts = list(cache_dir.glob("*_transcript.txt"))
        stats["youtube"]["transcripts"] = len(transcripts)
        stats["youtube"]["size_kb"] = sum(f.stat().st_size for f in transcripts) // 1024

    # Sentiment files
    sentiment_dir = DATA_DIR / "sentiment"
    if sentiment_dir.exists():
        stats["reddit"]["count"] = len(list(sentiment_dir.glob("reddit_*.json")))
        stats["news"]["count"] = len(list(sentiment_dir.glob("news_*.json")))

    return stats


def calculate_unified_system_health() -> dict[str, Any]:
    """
    Calculate unified system health status.
    Returns single authoritative status instead of mixed signals.

    Health levels:
    - OPERATIONAL: All systems working
    - DEGRADED: Some systems have issues
    - CRITICAL: Major systems failing
    """
    health = {
        "status": "OPERATIONAL",
        "emoji": "‚úÖ",
        "issues": [],
        "components": {
            "automation": {"status": "unknown", "detail": ""},
            "langsmith": {"status": "unknown", "detail": ""},
            "github_actions": {"status": "unknown", "detail": ""},
            "data_freshness": {"status": "unknown", "detail": ""},
        },
    }

    # Check LangSmith initialization
    try:
        import os

        langsmith_key = os.getenv("LANGCHAIN_API_KEY", "")
        if langsmith_key:
            health["components"]["langsmith"] = {
                "status": "ok",
                "detail": "API key configured",
            }
        else:
            health["components"]["langsmith"] = {
                "status": "warning",
                "detail": "API key not set",
            }
            health["issues"].append("LangSmith API key not configured")
    except Exception as e:
        health["components"]["langsmith"] = {"status": "error", "detail": str(e)}
        health["issues"].append(f"LangSmith check failed: {e}")

    # Check data freshness
    try:
        system_state_file = DATA_DIR / "system_state.json"
        if system_state_file.exists():
            import time

            file_age_hours = (time.time() - system_state_file.stat().st_mtime) / 3600
            if file_age_hours < 24:
                health["components"]["data_freshness"] = {
                    "status": "ok",
                    "detail": f"Updated {file_age_hours:.1f}h ago",
                }
            elif file_age_hours < 72:
                health["components"]["data_freshness"] = {
                    "status": "warning",
                    "detail": f"Updated {file_age_hours:.1f}h ago",
                }
                health["issues"].append(f"Data may be stale ({file_age_hours:.1f}h old)")
            else:
                health["components"]["data_freshness"] = {
                    "status": "error",
                    "detail": f"Updated {file_age_hours:.1f}h ago",
                }
                health["issues"].append(f"Data is stale ({file_age_hours:.1f}h old)")
        else:
            health["components"]["data_freshness"] = {
                "status": "error",
                "detail": "system_state.json not found",
            }
            health["issues"].append("system_state.json not found")
    except Exception as e:
        health["components"]["data_freshness"] = {"status": "error", "detail": str(e)}

    # Determine overall status
    error_count = sum(1 for c in health["components"].values() if c["status"] == "error")
    warning_count = sum(1 for c in health["components"].values() if c["status"] == "warning")

    if error_count >= 2:
        health["status"] = "CRITICAL"
        health["emoji"] = "üö®"
    elif error_count >= 1 or warning_count >= 2:
        health["status"] = "DEGRADED"
        health["emoji"] = "‚ö†Ô∏è"
    else:
        health["status"] = "OPERATIONAL"
        health["emoji"] = "‚úÖ"

    return health


def format_gated_metric(
    value: float,
    threshold: int,
    current_count: int,
    format_str: str = "{:.2f}",
    metric_name: str = "metric",
) -> str:
    """
    Format metric with investor-grade gating.

    If below threshold: shows "Waiting for ‚â•N trades"
    If at threshold: shows actual value
    """
    if current_count >= threshold:
        return format_str.format(value)
    else:
        return f"*Waiting for ‚â•{threshold} trades*"


def load_trade_data() -> list[dict[str, Any]]:
    """Load all trade data from trade log files and system_state."""
    trades = []

    # Load from daily trade files
    trade_files = sorted(DATA_DIR.glob("trades_*.json"))
    for trade_file in trade_files:
        try:
            with open(trade_file) as f:
                daily_trades = json.load(f)
                if isinstance(daily_trades, list):
                    trades.extend(daily_trades)
                elif isinstance(daily_trades, dict):
                    trades.append(daily_trades)
        except Exception:
            continue

    # Load closed trades from system_state.json (these have attribution metadata)
    system_state = load_json_file(DATA_DIR / "system_state.json")
    if system_state:
        performance = system_state.get("performance", {})
        closed_trades = performance.get("closed_trades", [])
        # Add closed trades that aren't already in the list
        existing_symbols_dates = {
            (t.get("symbol"), t.get("entry_date"))
            for t in trades
            if t.get("symbol") and t.get("entry_date")
        }
        for closed_trade in closed_trades:
            key = (closed_trade.get("symbol"), closed_trade.get("entry_date"))
            if key not in existing_symbols_dates:
                trades.append(closed_trade)

    return trades


def calculate_win_rate_from_trades(
    trades: list[dict[str, Any]],
) -> tuple[float, int, int]:
    """
    Calculate win rate from actual trade data.

    Returns:
        (win_rate_pct, winning_trades, total_closed_trades)
    """
    closed_trades = [
        t for t in trades if t.get("status", "").lower() == "filled" and t.get("pl") is not None
    ]

    if not closed_trades:
        return 0.0, 0, 0

    winning_trades = [t for t in closed_trades if t.get("pl", 0) > 0]
    total_closed = len(closed_trades)
    wins = len(winning_trades)

    win_rate = (wins / total_closed * 100) if total_closed > 0 else 0.0

    return win_rate, wins, total_closed


def format_statistically_significant(
    value: float, threshold: int, current_count: int, format_str: str = "{:.2f}"
) -> str:
    """
    Format metric with statistical significance indicator.

    Returns formatted value if significant, otherwise "Insufficient data" badge.
    """
    if current_count >= threshold:
        return format_str.format(value)
    else:
        return f"‚ö†Ô∏è Insufficient data (need ‚â•{threshold}, have {current_count})"


def calculate_ai_attribution_enhanced(trades: list[dict[str, Any]]) -> dict[str, Any]:
    """
    Calculate per-agent P&L attribution with enhanced metadata.

    Groups trades by decision maker (investor-grade attribution):
    - RL Policy: Reinforcement learning agent decisions
    - Momentum Heuristic: Rule-based momentum strategy
    - LLM Analyst: Claude/GPT-based analysis
    - Fallback Strategy: Default Python strategy when AI unavailable
    - Unknown: Trades without attribution metadata

    This answers: "Who made the call?" for each trade.
    """
    agent_attribution = defaultdict(
        lambda: {
            "trades": 0,
            "closed_trades": 0,
            "winning_trades": 0,
            "losing_trades": 0,
            "total_pl": 0.0,
            "avg_pl": 0.0,
            "win_rate": 0.0,
            "gross_profit": 0.0,
            "gross_loss": 0.0,
            "profit_factor": 0.0,
            "langsmith_traces": 0,
            "vertex_jobs": 0,
            "estimated_cost": 0.0,
            "display_name": "",  # Human-readable name
            "decision_type": "",  # AI or Rules
        }
    )

    # Human-readable names for agents
    agent_display_names = {
        "rl_policy": ("ü§ñ RL Policy", "AI"),
        "llm_analyst": ("üß† LLM Analyst", "AI"),
        "momentum_heuristic": ("üìä Momentum Rules", "Rules"),
        "fallback": ("‚öôÔ∏è Fallback Strategy", "Rules"),
        "unknown": ("‚ùì Unknown", "Unattributed"),
    }

    for trade in trades:
        # Determine agent type from trade metadata
        agent_type = "unknown"

        # Check attribution_metadata first
        attribution = trade.get("attribution_metadata", {})
        if attribution:
            # Check for gate/agent information
            gate2 = attribution.get("gate2_rl", {})
            gate3 = attribution.get("gate3_llm", {})
            gate1 = attribution.get("gate1_momentum", {})

            if gate2 and gate2.get("decision") == "APPROVE":
                agent_type = "rl_policy"
            elif gate3 and gate3.get("decision") == "APPROVE":
                agent_type = "llm_analyst"
            elif gate1 and gate1.get("decision") == "APPROVE":
                agent_type = "momentum_heuristic"
        else:
            # Fallback to agent_type field
            agent_type_raw = trade.get("agent_type", "unknown")
            if "rl" in agent_type_raw.lower() or "reinforcement" in agent_type_raw.lower():
                agent_type = "rl_policy"
            elif "llm" in agent_type_raw.lower() or "claude" in agent_type_raw.lower():
                agent_type = "llm_analyst"
            elif "heuristic" in agent_type_raw.lower():
                agent_type = "heuristic"
            elif "fallback" in agent_type_raw.lower():
                agent_type = "fallback"
            else:
                agent_type = "unknown"

        agent_data = agent_attribution[agent_type]
        agent_data["trades"] += 1

        # Set display name and decision type
        if agent_type in agent_display_names:
            agent_data["display_name"] = agent_display_names[agent_type][0]
            agent_data["decision_type"] = agent_display_names[agent_type][1]

        # Only count closed trades for P&L
        if trade.get("pl") is not None:
            pl = trade.get("pl", 0.0)
            agent_data["closed_trades"] += 1
            agent_data["total_pl"] += pl

            if pl > 0:
                agent_data["winning_trades"] += 1
                agent_data["gross_profit"] += pl
            else:
                agent_data["losing_trades"] += 1
                agent_data["gross_loss"] += abs(pl)

        # Count LangSmith traces and Vertex jobs
        if attribution:
            if attribution.get("langsmith_trace_id"):
                agent_data["langsmith_traces"] += 1
            if attribution.get("vertex_job_id"):
                agent_data["vertex_jobs"] += 1

        # Estimate cost
        if agent_type == "llm_analyst":
            agent_data["estimated_cost"] += 0.01
        elif agent_type == "rl_policy":
            agent_data["estimated_cost"] += 0.001

    # Calculate derived metrics
    for agent_type, agent_data in agent_attribution.items():
        if agent_data["closed_trades"] > 0:
            agent_data["avg_pl"] = agent_data["total_pl"] / agent_data["closed_trades"]
            agent_data["win_rate"] = (
                agent_data["winning_trades"] / agent_data["closed_trades"] * 100
            )
            if agent_data["gross_loss"] > 0:
                agent_data["profit_factor"] = agent_data["gross_profit"] / agent_data["gross_loss"]

        # Capital efficiency: return per $ of compute cost
        if agent_data["estimated_cost"] > 0:
            agent_data["capital_efficiency"] = agent_data["total_pl"] / agent_data["estimated_cost"]
        else:
            agent_data["capital_efficiency"] = float("inf") if agent_data["total_pl"] > 0 else 0.0

    return dict(agent_attribution)


def calculate_performance_attribution(
    trades: list[dict[str, Any]],
) -> dict[str, dict[str, Any]]:
    """Calculate performance attribution by strategy and asset."""
    attribution = defaultdict(
        lambda: {
            "trades": 0,
            "wins": 0,
            "losses": 0,
            "total_pl": 0.0,
            "avg_pl": 0.0,
            "win_rate": 0.0,
            "symbols": defaultdict(lambda: {"trades": 0, "pl": 0.0}),
        }
    )

    for trade in trades:
        if trade.get("pl") is None:
            continue

        tier = trade.get("tier", "UNKNOWN")
        symbol = trade.get("symbol", "UNKNOWN")
        pl = trade.get("pl", 0.0)

        attribution[tier]["trades"] += 1
        attribution[tier]["total_pl"] += pl
        attribution[tier]["symbols"][symbol]["trades"] += 1
        attribution[tier]["symbols"][symbol]["pl"] += pl

        if pl > 0:
            attribution[tier]["wins"] += 1
        else:
            attribution[tier]["losses"] += 1

    # Calculate averages and win rates
    for tier_data in attribution.values():
        if tier_data["trades"] > 0:
            tier_data["avg_pl"] = tier_data["total_pl"] / tier_data["trades"]
            tier_data["win_rate"] = (
                (tier_data["wins"] / tier_data["trades"] * 100) if tier_data["trades"] > 0 else 0.0
            )

    return dict(attribution)


def generate_equity_curve_chart(
    equity_curve: list[float], width: int = 60, height: int = 10
) -> str:
    """
    Generate ASCII equity curve chart.

    Args:
        equity_curve: List of portfolio values
        width: Chart width in characters
        height: Chart height in lines

    Returns:
        ASCII chart string
    """
    if len(equity_curve) < 2:
        return "  (Insufficient data - need at least 2 data points)"

    equity_array = np.array(equity_curve)
    min_val = np.min(equity_array)
    max_val = np.max(equity_array)
    range_val = max_val - min_val

    if range_val == 0:
        return "  (No variation in equity curve)"

    # Normalize to chart dimensions
    normalized = ((equity_array - min_val) / range_val) * (height - 1)

    # Create chart grid
    chart = [[" " for _ in range(width)] for _ in range(height)]

    # Plot points
    for i in range(len(normalized)):
        x = int((i / len(normalized)) * (width - 1))
        y = int(normalized[i])
        y = height - 1 - y  # Flip Y axis
        if 0 <= x < width and 0 <= y < height:
            chart[y][x] = "‚ñà"

    # Connect points
    for i in range(len(normalized) - 1):
        x1 = int((i / len(normalized)) * (width - 1))
        x2 = int(((i + 1) / len(normalized)) * (width - 1))
        y1 = int(normalized[i])
        y2 = int(normalized[i + 1])
        y1 = height - 1 - y1
        y2 = height - 1 - y2

        if x1 != x2:
            steps = abs(x2 - x1)
            for step in range(steps + 1):
                x = x1 + int((x2 - x1) * step / steps)
                y = y1 + int((y2 - y1) * step / steps)
                if 0 <= x < width and 0 <= y < height:
                    chart[y][x] = "‚ñà"

    # Convert to string
    chart_lines = ["".join(row) for row in chart]

    # Add labels
    result = f"  ${min_val:,.0f} ‚î§{' ' * (width - 20)}‚î§ ${max_val:,.0f}\n"
    result += "\n".join(f"     ‚îÇ{line}" for line in chart_lines)

    return result


def generate_returns_distribution_chart(
    returns: list[float], width: int = 50, height: int = 10
) -> str:
    """Generate ASCII histogram of returns distribution."""
    if len(returns) < 3:
        return "  (Insufficient data for distribution)"

    returns_array = np.array(returns)

    # Create bins
    min_ret = np.min(returns_array)
    max_ret = np.max(returns_array)
    bins = np.linspace(min_ret, max_ret, width)

    # Count frequencies
    hist, _ = np.histogram(returns_array, bins=bins)
    max_freq = np.max(hist) if len(hist) > 0 else 1

    # Normalize to chart height
    normalized = (hist / max_freq * height).astype(int)

    # Create chart
    chart_lines = []
    for y in range(height - 1, -1, -1):
        line = "  "
        for freq in normalized:
            line += "‚ñà" if freq > y else " "
        chart_lines.append(line)

    # Add labels
    result = f"  {min_ret * 100:.2f}% {' ' * (width - 20)} {max_ret * 100:.2f}%\n"
    result += "\n".join(chart_lines)

    return result


def generate_risk_heatmap(risk_metrics: dict[str, float]) -> str:
    """
    Generate ASCII risk heatmap.

    Returns:
        ASCII heatmap string
    """
    metrics = [
        ("Max Drawdown", risk_metrics.get("max_drawdown_pct", 0.0), 10.0),
        ("VaR (95%)", risk_metrics.get("var_95", 0.0), 5.0),
        ("Volatility", risk_metrics.get("volatility", 0.0), 20.0),
        ("Ulcer Index", risk_metrics.get("ulcer_index", 0.0), 10.0),
    ]

    result = "  Risk Level:\n"
    for name, value, threshold in metrics:
        level = min(100, (value / threshold) * 100) if threshold > 0 else 0
        bars = int(level / 5)
        bar_char = "‚ñà" if level < 50 else "‚ñà" if level < 75 else "‚ñà"
        status = "‚úÖ" if level < 50 else "‚ö†Ô∏è" if level < 75 else "üö®"
        result += f"  {name:20s} [{bar_char * bars:<20}] {level:.1f}% {status}\n"

    return result


def generate_risk_alerts(
    risk_metrics: dict[str, float], win_rate: float, total_trades: int
) -> list[str]:
    """Generate actionable risk alerts."""
    alerts = []

    # Drawdown alert
    if risk_metrics.get("max_drawdown_pct", 0.0) > 5.0:
        alerts.append(
            f"üö® **Drawdown Alert**: Max drawdown is {risk_metrics.get('max_drawdown_pct', 0.0):.2f}% (threshold: 5%). Consider reducing position sizes."
        )

    # Win rate alert
    if win_rate < 40.0 and total_trades >= 10:
        alerts.append(
            f"‚ö†Ô∏è **Win Rate Alert**: Win rate is {win_rate:.1f}% (target: >55%). Review strategy logic and entry criteria."
        )

    # Volatility alert
    if risk_metrics.get("volatility", 0.0) > 20.0:
        alerts.append(
            f"‚ö†Ô∏è **Volatility Alert**: Annualized volatility is {risk_metrics.get('volatility', 0.0):.2f}% (threshold: 20%). Consider diversification."
        )

    # Low trade count alert
    if total_trades < 5:
        alerts.append(
            f"‚ÑπÔ∏è **Data Alert**: Only {total_trades} trades recorded. Metrics will become more reliable with more trade data."
        )

    # Sharpe ratio alert
    if risk_metrics.get("sharpe_ratio", 0.0) < 0.5 and total_trades >= 10:
        alerts.append(
            f"‚ö†Ô∏è **Risk-Adjusted Return Alert**: Sharpe ratio is {risk_metrics.get('sharpe_ratio', 0.0):.2f} (target: >1.0). Review risk management."
        )

    return alerts if alerts else ["‚úÖ No critical risk alerts at this time"]


def calculate_market_regime() -> dict[str, Any]:
    """
    Calculate current market regime based on SPY performance and VIX levels.

    Returns:
        Dictionary with regime classification and metadata
    """
    try:
        from datetime import timedelta

        import yfinance as yf

        # Get SPY and VIX data
        end_date = datetime.now()
        start_date = end_date - timedelta(days=60)  # Get 60 days for 20-day calculation

        spy = yf.Ticker("SPY")
        spy_data = spy.history(start=start_date, end=end_date)

        vix = yf.Ticker("^VIX")
        vix_data = vix.history(start=start_date, end=end_date)

        if len(spy_data) < 20 or len(vix_data) < 1:
            return {
                "regime": "Unknown",
                "volatility": "Unknown",
                "display": "‚ö™ Unknown (Insufficient Data)",
                "spy_return_20d": 0.0,
                "vix_level": 0.0,
                "edge_notes": "Insufficient market data for regime detection",
            }

        # Calculate 20-day SPY return
        spy_return_20d = ((spy_data["Close"].iloc[-1] / spy_data["Close"].iloc[-20]) - 1) * 100

        # Get current VIX level
        vix_level = vix_data["Close"].iloc[-1]

        # Classify regime
        if spy_return_20d > 2.0:
            trend_regime = "Bull"
        elif spy_return_20d < -2.0:
            trend_regime = "Bear"
        else:
            trend_regime = "Sideways"

        # Classify volatility
        vol_regime = "High Vol" if vix_level > 25 else "Low Vol"

        # Combine regimes
        full_regime = f"{trend_regime} Market ({vol_regime})"

        # Select emoji and edge notes
        if trend_regime == "Bull" and vol_regime == "Low Vol":
            emoji = "üü¢"
            edge_notes = "Optimal conditions for momentum strategies. Focus on breakout entries."
        elif trend_regime == "Bull" and vol_regime == "High Vol":
            emoji = "üü°"
            edge_notes = (
                "Volatile rally - use wider stops and smaller positions. Watch for whipsaws."
            )
        elif trend_regime == "Bear" and vol_regime == "Low Vol":
            emoji = "üü†"
            edge_notes = (
                "Grinding bear market - consider cash preservation. Short-term mean reversion only."
            )
        elif trend_regime == "Bear" and vol_regime == "High Vol":
            emoji = "üî¥"
            edge_notes = (
                "High-risk environment - reduce exposure significantly. Wait for stabilization."
            )
        elif trend_regime == "Sideways" and vol_regime == "Low Vol":
            emoji = "‚ö™"
            edge_notes = "Range-bound market - focus on mean reversion and quick profits."
        else:  # Sideways + High Vol
            emoji = "üü£"
            edge_notes = "Choppy conditions - difficult environment. Reduce trade frequency."

        return {
            "regime": trend_regime,
            "volatility": vol_regime,
            "display": f"{emoji} {full_regime}",
            "spy_return_20d": spy_return_20d,
            "vix_level": vix_level,
            "edge_notes": edge_notes,
        }

    except ImportError:
        return {
            "regime": "Unknown",
            "volatility": "Unknown",
            "display": "‚ö†Ô∏è Unknown (yfinance not available)",
            "spy_return_20d": 0.0,
            "vix_level": 0.0,
            "edge_notes": "Install yfinance to enable market regime detection",
        }
    except Exception as e:
        return {
            "regime": "Unknown",
            "volatility": "Unknown",
            "display": f"‚ö†Ô∏è Unknown (Error: {str(e)})",
            "spy_return_20d": 0.0,
            "vix_level": 0.0,
            "edge_notes": f"Error detecting regime: {str(e)}",
        }


def calculate_strategy_level_insights(
    trades: list[dict[str, Any]], attribution: dict[str, dict[str, Any]]
) -> dict[str, dict[str, Any]]:
    """
    Calculate strategy-level insights: win rate, expectancy, avg duration, risk/reward.

    Returns:
        Dict mapping strategy name to metrics dict with:
        - win_rate: Win rate percentage
        - expectancy: Expected $ per trade
        - avg_duration_hours: Average trade duration in hours
        - risk_reward_ratio: Risk per trade vs return per trade
        - trade_count: Number of trades for this strategy
    """
    strategy_insights = {}

    # Map tier names to readable strategy names
    tier_to_strategy = {
        "TIER1": "Tier 1 Core",
        "TIER2": "Tier 2 Growth",
        "TIER5": "Tier 5 Crypto",
        "UNKNOWN": "Unknown",
    }

    # Calculate metrics per tier from trades
    tier_metrics = defaultdict(
        lambda: {
            "trades": [],
            "total_pl": 0.0,
            "wins": 0,
            "losses": 0,
            "total_duration_hours": 0.0,
            "total_risk": 0.0,
            "total_return": 0.0,
        }
    )

    for trade in trades:
        if trade.get("pl") is None:
            continue

        tier = trade.get("tier", "UNKNOWN")
        pl = trade.get("pl", 0.0)

        tier_metrics[tier]["trades"].append(trade)
        tier_metrics[tier]["total_pl"] += pl

        if pl > 0:
            tier_metrics[tier]["wins"] += 1
            tier_metrics[tier]["total_return"] += abs(pl)
        else:
            tier_metrics[tier]["losses"] += 1
            tier_metrics[tier]["total_risk"] += abs(pl)

        # Calculate duration if entry and exit times available
        if trade.get("entry_date") and trade.get("exit_date"):
            try:
                from datetime import datetime as dt

                entry = dt.fromisoformat(trade["entry_date"].replace("Z", "+00:00"))
                exit_dt = dt.fromisoformat(trade["exit_date"].replace("Z", "+00:00"))
                duration_hours = (exit_dt - entry).total_seconds() / 3600
                tier_metrics[tier]["total_duration_hours"] += duration_hours
            except Exception:
                pass

    # Calculate derived metrics for each tier
    for tier, metrics in tier_metrics.items():
        trade_count = len(metrics["trades"])
        if trade_count == 0:
            continue

        strategy_name = tier_to_strategy.get(tier, tier)

        # Win rate
        win_rate = (metrics["wins"] / trade_count * 100) if trade_count > 0 else 0.0

        # Expectancy (expected $ per trade)
        expectancy = metrics["total_pl"] / trade_count if trade_count > 0 else 0.0

        # Average duration
        avg_duration = (
            metrics["total_duration_hours"] / trade_count
            if trade_count > 0 and metrics["total_duration_hours"] > 0
            else 0.0
        )

        # Risk/Reward ratio
        risk_reward = (
            metrics["total_return"] / metrics["total_risk"] if metrics["total_risk"] > 0 else 0.0
        )

        strategy_insights[strategy_name] = {
            "win_rate": win_rate,
            "expectancy": expectancy,
            "avg_duration_hours": avg_duration,
            "risk_reward_ratio": risk_reward,
            "trade_count": trade_count,
        }

    # Add placeholder data for strategies with no trades (use backtest estimates)
    all_strategies = ["Tier 1 Core", "Tier 2 Growth", "Tier 5 Crypto"]
    for strategy in all_strategies:
        if strategy not in strategy_insights:
            # Use backtest-based estimates for strategies with no data
            if strategy == "Tier 1 Core":
                # Based on SPY/QQQ/VOO backtest: 62.2% win rate, $0.28/trade
                strategy_insights[strategy] = {
                    "win_rate": 62.2,
                    "expectancy": 0.28,
                    "avg_duration_hours": 24.0,  # Assume 1-day holds
                    "risk_reward_ratio": 1.5,  # Estimated
                    "trade_count": 0,
                    "is_backtest": True,
                }
            else:
                # Pending for other strategies
                strategy_insights[strategy] = {
                    "win_rate": None,
                    "expectancy": None,
                    "avg_duration_hours": None,
                    "risk_reward_ratio": None,
                    "trade_count": 0,
                    "is_backtest": False,
                }

    return strategy_insights


def generate_ai_insights_enhanced(
    trades: list[dict[str, Any]],
    win_rate: float,
    total_trades: int,
    attribution: dict[str, dict[str, Any]],
    risk_metrics: dict[str, float],
) -> dict[str, Any]:
    """Generate enhanced AI insights with trade analysis."""
    insights = {
        "summary": "",
        "key_findings": [],
        "recommendations": [],
        "trade_analysis": [],
    }

    if total_trades == 0:
        insights["summary"] = "No trades executed yet. System is ready for trading."
        insights["key_findings"] = ["Waiting for first trade execution"]
        insights["recommendations"] = ["Monitor system for first trade opportunity"]
        return insights

    # Analyze best/worst performing strategies
    best_tier = max(
        attribution.items(), key=lambda x: x[1].get("total_pl", 0.0), default=(None, {})
    )
    worst_tier = min(
        attribution.items(), key=lambda x: x[1].get("total_pl", 0.0), default=(None, {})
    )

    # Generate summary
    if win_rate >= 55:
        insights["summary"] = f"‚úÖ Portfolio is performing well with {win_rate:.1f}% win rate. "
    elif win_rate >= 40:
        insights["summary"] = f"‚ö†Ô∏è Portfolio win rate is {win_rate:.1f}% - below target of 55%. "
    else:
        insights["summary"] = (
            f"üö® Portfolio win rate is {win_rate:.1f}% - significant improvement needed. "
        )

    insights["summary"] += f"Total trades: {total_trades}. "

    if best_tier[0]:
        insights["summary"] += (
            f"Best performing strategy: {best_tier[0]} (${best_tier[1].get('total_pl', 0.0):+.2f})."
        )

    # Key findings
    if best_tier[0] and best_tier[1].get("total_pl", 0) > 0:
        insights["key_findings"].append(
            f"‚úÖ {best_tier[0]} is the top performer with ${best_tier[1].get('total_pl', 0.0):+.2f} P/L"
        )

    if worst_tier[0] and worst_tier[1].get("total_pl", 0) < 0:
        insights["key_findings"].append(
            f"‚ö†Ô∏è {worst_tier[0]} is underperforming with ${worst_tier[1].get('total_pl', 0.0):+.2f} P/L"
        )

    # Win rate analysis
    if win_rate < 55 and total_trades >= 10:
        insights["key_findings"].append(f"‚ö†Ô∏è Win rate ({win_rate:.1f}%) is below target (55%)")

    # Recommendations
    if win_rate < 40 and total_trades >= 10:
        insights["recommendations"].append("Review entry criteria - consider tightening filters")
        insights["recommendations"].append("Analyze losing trades to identify common patterns")

    if best_tier[0] and best_tier[1].get("win_rate", 0) > 60:
        insights["recommendations"].append(
            f"Consider increasing allocation to {best_tier[0]} (win rate: {best_tier[1].get('win_rate', 0):.1f}%)"
        )

    if risk_metrics.get("max_drawdown_pct", 0.0) > 5.0:
        insights["recommendations"].append("Reduce position sizes to limit drawdown")

    # Trade analysis
    recent_trades = sorted(trades, key=lambda x: x.get("timestamp", ""), reverse=True)[:5]
    for trade in recent_trades:
        symbol = trade.get("symbol", "UNKNOWN")
        tier = trade.get("tier", "UNKNOWN")
        pl = trade.get("pl", 0.0)
        status = "‚úÖ" if pl > 0 else "‚ùå"
        insights["trade_analysis"].append(f"{status} {symbol} ({tier}): ${pl:+.2f}")

    return insights


def generate_world_class_dashboard() -> str:
    """Generate world-class dashboard markdown."""

    # Load data
    system_state = load_json_file(DATA_DIR / "system_state.json")
    perf_log = load_json_file(DATA_DIR / "performance_log.json")
    challenge_start = load_json_file(DATA_DIR / "challenge_start.json")
    trades = load_trade_data()
    rag_stats = get_rag_knowledge_stats()

    # Extract equity curve
    equity_curve = []
    if isinstance(perf_log, list) and len(perf_log) > 0:
        equity_curve = [
            entry.get("equity", 100000.0) for entry in perf_log if entry.get("equity") is not None
        ]

    # Fallback: if no equity curve data, try to get from system state
    if not equity_curve:
        current_equity = system_state.get("account", {}).get("current_equity", 100000.0)
        if current_equity:
            equity_curve = [current_equity]

    # Initialize analytics
    analytics = WorldClassAnalytics() if WorldClassAnalytics else None

    # Calculate basic metrics
    account = system_state.get("account", {})
    total_pl = account.get("total_pl", 0.0)
    current_equity = account.get("current_equity", 100000.0)
    starting_balance = challenge_start.get("starting_balance", 100000.0)

    # Calculate win rate from actual trades
    win_rate, winning_trades, total_closed_trades = calculate_win_rate_from_trades(trades)

    # Performance attribution - use both strategy-level and trade-level attribution
    attribution = calculate_performance_attribution(trades)

    # Enhanced AI attribution
    # Enhanced trade-level attribution with gate/agent breakdown
    trade_level_attribution = {}
    if analytics and trades:
        closed_trades_with_attribution = [
            t for t in trades if t.get("pl") is not None and t.get("attribution_metadata")
        ]
        if closed_trades_with_attribution:
            trade_level_attribution = analytics.calculate_trade_level_attribution(
                closed_trades_with_attribution
            )

    # Calculate returns for analytics
    returns = []
    if len(equity_curve) > 1:
        returns = [
            (equity_curve[i] - equity_curve[i - 1]) / equity_curve[i - 1]
            for i in range(1, len(equity_curve))
        ]

    # Calculate risk metrics
    risk_metrics_dict = {}
    if analytics and len(equity_curve) > 1:
        risk_metrics = analytics.calculate_risk_metrics(equity_curve)
        risk_metrics_dict = {
            "max_drawdown_pct": risk_metrics.max_drawdown_pct,
            "ulcer_index": risk_metrics.ulcer_index,
            "sortino_ratio": risk_metrics.sortino_ratio,
            "sharpe_ratio": risk_metrics.sharpe_ratio,
            "var_95": risk_metrics.var_95,
            "var_99": risk_metrics.var_99,
            "cvar_95": risk_metrics.cvar_95,
            "volatility": risk_metrics.volatility,
            "calmar_ratio": risk_metrics.calmar_ratio,
        }
    else:
        risk_metrics_dict = {
            "max_drawdown_pct": 0.0,
            "ulcer_index": 0.0,
            "sortino_ratio": 0.0,
            "sharpe_ratio": 0.0,
            "var_95": 0.0,
            "var_99": 0.0,
            "cvar_95": 0.0,
            "volatility": 0.0,
            "calmar_ratio": 0.0,
        }

    # Monte Carlo forecast
    forecast_dict = {}
    if analytics and len(returns) > 10:
        forecast = analytics.monte_carlo_forecast(returns)
        forecast_dict = {
            "expected_profit_7d": forecast.expected_profit_7d[0] * current_equity,
            "expected_profit_30d": forecast.expected_profit_30d[0] * current_equity,
            "confidence_interval_95_lower": forecast.confidence_interval_95[0] * current_equity,
            "confidence_interval_95_upper": forecast.confidence_interval_95[1] * current_equity,
            "drawdown_probability": forecast.drawdown_probability,
            "edge_drift_score": forecast.edge_drift_score,
        }
    else:
        # Fallback to backtest-based projections (62.2% win rate, 2.18 Sharpe)
        expected_daily_profit = 0.28  # ~$0.28/day based on backtest
        forecast_dict = {
            "expected_profit_7d": expected_daily_profit * 7,  # ~$1.96/week
            "expected_profit_30d": expected_daily_profit * 30,  # ~$8.40/month
            "confidence_interval_95_lower": expected_daily_profit * 7 * 0.5,
            "confidence_interval_95_upper": expected_daily_profit * 7 * 1.5,
            "drawdown_probability": 2.0,  # Low based on backtest
            "edge_drift_score": 0.0,
        }

    # Enhanced AI insights
    enhanced_insights = generate_ai_insights_enhanced(
        trades, win_rate, total_closed_trades, attribution, risk_metrics_dict
    )

    # Risk alerts
    risk_alerts = generate_risk_alerts(risk_metrics_dict, win_rate, total_closed_trades)

    # Strategy-level insights
    strategy_insights = calculate_strategy_level_insights(trades, attribution)

    # Market regime detection
    market_regime = calculate_market_regime()

    # Performance metrics
    performance = system_state.get("performance", {})
    total_trades = performance.get("total_trades", total_closed_trades)

    # Calculate averages
    trading_days = len(perf_log) if isinstance(perf_log, list) and perf_log else 1
    avg_daily_profit = total_pl / trading_days if trading_days > 0 else 0.0
    north_star_target = 100.0
    progress_pct = (avg_daily_profit / north_star_target * 100) if north_star_target > 0 else 0.0

    if total_pl > 0 and progress_pct < 0.01:
        progress_pct = max(0.01, (total_pl / north_star_target) * 100)

    # Challenge info
    challenge = system_state.get("challenge", {})
    current_day = challenge.get("current_day", 1)
    total_days = challenge.get("total_days", 90)

    # Calculate today's performance metrics
    today_str = date.today().isoformat()
    today_trades_file = DATA_DIR / f"trades_{today_str}.json"
    today_trades = load_json_file(today_trades_file)
    today_trade_count = len(today_trades) if isinstance(today_trades, list) else 0

    today_perf = None
    today_equity = current_equity
    today_pl = 0.0
    today_pl_pct = 0.0

    if isinstance(perf_log, list) and perf_log:
        # Find today's entry in performance log
        for entry in reversed(perf_log):
            if entry.get("date") == today_str:
                today_perf = entry
                today_equity = entry.get("equity", current_equity)
                today_pl = entry.get("pl", 0.0)
                today_pl_pct = entry.get("pl_pct", 0.0)  # Already in percentage
                break

        # If no entry for today, calculate from yesterday
        if today_perf is None and len(perf_log) > 0:
            yesterday_perf = perf_log[-1]
            yesterday_equity = yesterday_perf.get("equity", starting_balance)
            today_equity = current_equity
            today_pl = current_equity - yesterday_equity
            today_pl_pct = ((today_pl / yesterday_equity) * 100) if yesterday_equity > 0 else 0.0

    # Get today's date string for display
    today_display = date.today().strftime("%Y-%m-%d (%A)")

    # Generate dashboard
    now = datetime.now()

    # Progress bar
    north_star_bars = 1 if total_pl > 0 and progress_pct < 5.0 else min(int(progress_pct / 5), 20)
    north_star_bar = "‚ñà" * north_star_bars + "‚ñë" * (20 - north_star_bars)
    display_progress_pct = max(progress_pct, 0.01) if total_pl > 0 else progress_pct

    # Performance attribution table
    attribution_table = ""
    if attribution:
        attribution_table = (
            "\n| Strategy | Trades | Wins | Losses | Win Rate | Total P/L | Avg P/L |\n"
        )
        attribution_table += (
            "|----------|--------|------|--------|----------|-----------|----------|\n"
        )
        for tier, data in sorted(
            attribution.items(), key=lambda x: x[1].get("total_pl", 0), reverse=True
        ):
            attribution_table += f"| **{tier}** | {data['trades']} | {data['wins']} | {data['losses']} | {data['win_rate']:.1f}% | ${data['total_pl']:+,.2f} | ${data['avg_pl']:+,.2f} |\n"

        # Add gate-level attribution if available
        if trade_level_attribution:
            by_gate = trade_level_attribution.get("by_gate", {})
            if by_gate:
                attribution_table += "\n### By Gate/Agent\n\n"
                attribution_table += "| Gate/Agent | Total P/L | Trades | Avg Metric |\n"
                attribution_table += "|------------|-----------|--------|------------|\n"
                for gate, data in sorted(
                    by_gate.items(), key=lambda x: x[1].get("total_pl", 0), reverse=True
                ):
                    gate_name = (
                        gate.replace("gate1_momentum", "Gate 1: Momentum")
                        .replace("gate2_rl", "Gate 2: RL Agent")
                        .replace("gate3_llm", "Gate 3: LLM Analyst")
                        .replace("gate4_risk", "Gate 4: Risk Manager")
                    )
                    attribution_table += f"| {gate_name} | ${data.get('total_pl', 0):+,.2f} | {data.get('trades', 0)} | {data.get('avg_metric', 0):.2f} |\n"

                # Add entry/exit/sizing breakdown
                entry_exit = trade_level_attribution.get("entry_exit_sizing", {})
                if entry_exit:
                    attribution_table += "\n### Entry/Exit/Sizing Contribution\n\n"
                    attribution_table += "| Factor | Contribution % | P/L Impact |\n"
                    attribution_table += "|--------|---------------|------------|\n"
                    attribution_table += f"| Entry Signal Quality | {entry_exit.get('entry_signal_contribution_pct', 0):.1f}% | ${entry_exit.get('entry_pl', 0):+,.2f} |\n"
                    attribution_table += f"| Exit Timing | {entry_exit.get('exit_signal_contribution_pct', 0):.1f}% | ${entry_exit.get('exit_pl', 0):+,.2f} |\n"
                    attribution_table += f"| Position Sizing | {entry_exit.get('position_sizing_contribution_pct', 0):.1f}% | ${entry_exit.get('sizing_pl', 0):+,.2f} |\n"
    else:
        attribution_table = "  (No trade data available for attribution analysis)"

    # Calculate unified system health
    system_health = calculate_unified_system_health()

    # Calculate tax optimization metrics
    tax_metrics = {}
    tax_recommendations = []
    pdt_status = {}
    if TaxOptimizer and trades:
        try:
            tax_optimizer = TaxOptimizer()

            # Process trades for tax tracking
            from datetime import datetime as dt

            for trade in trades:
                if (
                    trade.get("entry_date")
                    and trade.get("exit_date")
                    and trade.get("pl") is not None
                ):
                    try:
                        entry_date = dt.fromisoformat(trade["entry_date"].replace("Z", "+00:00"))
                        exit_date = dt.fromisoformat(trade["exit_date"].replace("Z", "+00:00"))
                        entry_price = trade.get("entry_price", 0.0)
                        exit_price = trade.get("exit_price", 0.0)
                        quantity = trade.get("quantity", 0.0)
                        trade_id = trade.get(
                            "trade_id",
                            f"{trade.get('symbol', 'UNKNOWN')}_{entry_date.isoformat()}",
                        )

                        # Record entry
                        tax_optimizer.record_trade_entry(
                            trade.get("symbol", "UNKNOWN"),
                            quantity,
                            entry_price,
                            entry_date,
                            trade_id,
                        )

                        # Record exit
                        tax_optimizer.record_trade_exit(
                            trade.get("symbol", "UNKNOWN"),
                            quantity,
                            exit_price,
                            exit_date,
                            trade_id,
                        )
                    except Exception as e:
                        logger.debug(f"Error processing trade for tax: {e}")

            # Get tax summary
            tax_metrics = tax_optimizer.get_tax_summary()

            # Check PDT status
            pdt_status = tax_optimizer.check_pdt_status(current_equity)

            # Get recommendations
            open_positions = system_state.get("performance", {}).get("open_positions", [])
            tax_recommendations = tax_optimizer.get_tax_optimization_recommendations(
                current_equity, open_positions
            )
        except Exception as e:
            logger.debug(f"Tax optimization calculation error: {e}")
            tax_metrics = {
                "total_trades": 0,
                "estimated_tax": 0.0,
                "after_tax_return": 0.0,
                "day_trade_count": 0,
            }
            pdt_status = {"status": "‚ö†Ô∏è Unable to calculate", "warnings": []}

    dashboard = f"""# üåü World-Class Trading Dashboard

**Last Updated**: {now.strftime("%Y-%m-%d %I:%M %p ET")}
**Auto-Updated**: Daily via GitHub Actions
**Dashboard Version**: World-Class Elite Analytics v2.0

"""

    # Add unified health banner (investor-grade: single source of truth)
    if system_health["status"] != "OPERATIONAL":
        dashboard += f"""
> {system_health["emoji"]} **SYSTEM STATUS: {system_health["status"]}**
>
"""
        for issue in system_health["issues"][:3]:  # Show top 3 issues
            dashboard += f"> - {issue}\n"
        dashboard += "\n"
    else:
        dashboard += f"""> {system_health["emoji"]} **SYSTEM STATUS: OPERATIONAL** - All monitoring systems active

"""

    dashboard += f"""---

## üìÖ Today's Performance

**Date**: {today_display}
| **Metric** | **Value** |
|------------|-----------|
| **Equity** | ${today_equity:,.2f} |
| **Total P/L** | ${total_pl:+,.2f} |
| **Daily P/L** | ${today_pl:+,.2f} ({today_pl_pct:+.2f}%) |
| **Trades Today** | {today_trade_count} |
| **Status** | {system_health["emoji"]} {system_health["status"]} |

---

## üå°Ô∏è Market Regime Detection

**Current Regime**: {market_regime["display"]}

| Metric | Value |
|--------|-------|
| **SPY 20-Day Return** | {market_regime["spy_return_20d"]:+.2f}% |
| **VIX Level** | {market_regime["vix_level"]:.2f} |
| **Market Regime** | {market_regime["regime"]} |
| **Volatility Regime** | {market_regime["volatility"]} |

**Regime-Specific Edge Notes**:
{market_regime["edge_notes"]}

---

## üíº Current Holdings

{holdings_section}

---

## üö® CRITICAL ISSUES - IMMEDIATE ATTENTION REQUIRED

"""
    # Check for critical issues
    critical_issues = []
    sharpe = risk_metrics_dict.get("sharpe_ratio", 0.0)

    if sharpe < 0:
        critical_issues.append(
            f"üö® **NEGATIVE SHARPE RATIO ({sharpe:.2f})**: Strategy is worse than random. "
            f"Taking massive risk for minimal reward. Better off with cash in savings account. "
            f"**Action**: Run post-mortem on every losing trade. Check if entry/exit logic is inverted."
        )

    if total_closed_trades > 0 and win_rate == 0.0:
        critical_issues.append(
            f"üö® **0% WIN RATE ({winning_trades}/{total_closed_trades} trades)**: Zero winning trades suggests "
            f"fundamental flaw in strategy. **Action**: Need 50+ trades for statistical significance. "
            f"Consider paper trading at higher frequency. Debug entry/exit logic."
        )
    elif total_closed_trades < 50:
        critical_issues.append(
            f"‚ö†Ô∏è **INSUFFICIENT SAMPLE SIZE ({total_closed_trades} trades)**: Need 50+ trades before metrics "
            f"are meaningful. Current win rate {win_rate:.1f}% is statistically insignificant."
        )

    if avg_daily_profit < 1.0:
        progress_to_target = (avg_daily_profit / 100.0) * 100
        critical_issues.append(
            f"‚ö†Ô∏è **FAR FROM TARGET**: ${avg_daily_profit:.2f}/day vs $100/day target ({progress_to_target:.2f}% of goal). "
            f"Gap suggests strategy fundamentals need rethinking, not just optimization."
        )

    # Check LangSmith status
    try:
        from scripts.monitor_training_and_update_dashboard import TrainingMonitor

        monitor = TrainingMonitor()
        if monitor.langsmith_monitor and monitor.langsmith_monitor.client is None:
            critical_issues.append(
                "‚ö†Ô∏è **LANGSMITH NOT INITIALIZED**: RL training observability broken. "
                "**Action**: Verify LANGCHAIN_API_KEY is set in GitHub Secrets."
            )
    except Exception:
        pass

    if critical_issues:
        dashboard += "### Critical Warnings\n\n"
        for issue in critical_issues:
            dashboard += f"{issue}\n\n"
    else:
        dashboard += "‚úÖ **No critical issues detected**\n\n"

    dashboard += f"""---

## üéØ North Star Goal

**Target**: **$100+/day profit**

| Metric | Current | Target | Progress |
|--------|---------|--------|----------|
| **Average Daily Profit** | ${avg_daily_profit:.2f}/day | $100.00/day | {display_progress_pct:.2f}% |
| **Total P/L** | ${total_pl:+,.2f} ({total_pl / starting_balance * 100:+.2f}%) | TBD | {"‚úÖ" if total_pl > 0 else "‚ö†Ô∏è"} |
| **Win Rate** | {win_rate:.1f}% ({winning_trades}/{total_closed_trades}) | >55% | {"‚úÖ" if win_rate >= 55 else "‚ö†Ô∏è" if win_rate >= 40 else "üö®"} |

**Progress Toward $100/Day Goal**: `{north_star_bar}` ({display_progress_pct:.2f}%)
*This shows how close your average daily profit is to the $100/day target*

---

## üìä Performance Attribution

### By Strategy

{attribution_table}

### ü§ñ AI Attribution (Per-Agent P&L)

"""

    # Add AI attribution section (investor-grade: "Who made the call?")
    # Calculate enhanced AI attribution with display names
    enhanced_ai_attribution = calculate_ai_attribution_enhanced(trades)

    if enhanced_ai_attribution:
        # Summary of AI vs Rules usage
        ai_trades = sum(
            d["trades"] for d in enhanced_ai_attribution.values() if d.get("decision_type") == "AI"
        )
        rules_trades = sum(
            d["trades"]
            for d in enhanced_ai_attribution.values()
            if d.get("decision_type") == "Rules"
        )
        unattributed_trades = sum(
            d["trades"]
            for d in enhanced_ai_attribution.values()
            if d.get("decision_type") == "Unattributed"
        )
        total_attr_trades = ai_trades + rules_trades + unattributed_trades

        if total_attr_trades > 0:
            ai_pct = (ai_trades / total_attr_trades * 100) if total_attr_trades > 0 else 0
            rules_pct = (rules_trades / total_attr_trades * 100) if total_attr_trades > 0 else 0
            dashboard += f"**Decision Breakdown**: ü§ñ AI: {ai_trades} ({ai_pct:.0f}%) | üìä Rules: {rules_trades} ({rules_pct:.0f}%) | ‚ùì Unattributed: {unattributed_trades}\n\n"

        dashboard += (
            "| Decision Maker | Type | Trades | Closed | Win Rate | Total P/L | Avg P/L | Cost |\n"
        )
        dashboard += (
            "|----------------|------|--------|--------|----------|-----------|---------|------|\n"
        )

        for agent_type, data in sorted(
            enhanced_ai_attribution.items(),
            key=lambda x: x[1].get("trades", 0),
            reverse=True,
        ):
            # Use enhanced display name if available, otherwise format the key
            agent_name = data.get("display_name") or agent_type.replace("_", " ").title()
            decision_type = data.get("decision_type") or "Unknown"

            # Gate win rate and P/L metrics until sufficient data
            if data["closed_trades"] >= STAT_THRESHOLDS.get("win_rate", 10):
                win_rate_display = f"{data['win_rate']:.1f}%"
            elif data["closed_trades"] > 0:
                win_rate_display = f"{data['win_rate']:.1f}%*"  # Asterisk = low confidence
            else:
                win_rate_display = "N/A"

            dashboard += f"| {agent_name} | {decision_type} | {data['trades']} | {data['closed_trades']} | {win_rate_display} | ${data['total_pl']:+,.2f} | ${data['avg_pl']:+,.2f} | ${data['estimated_cost']:.2f} |\n"

        dashboard += "\n*Win rates marked with * have low confidence (< 10 closed trades)*\n"

        dashboard += "\n**Observability**:\n"
        total_traces = sum(a.get("langsmith_traces", 0) for a in enhanced_ai_attribution.values())
        total_jobs = sum(a.get("vertex_jobs", 0) for a in enhanced_ai_attribution.values())
        dashboard += f"- LangSmith Traces: {total_traces}\n"
        dashboard += f"- Vertex AI Jobs: {total_jobs}\n"
    else:
        dashboard += (
            "‚ö†Ô∏è **No trade data available** - Attribution will populate once trades are executed\n\n"
        )

    dashboard += """

### Top Performing Assets

"""

    # Add top assets
    asset_performance = defaultdict(lambda: {"trades": 0, "pl": 0.0, "wins": 0})
    for trade in trades:
        if trade.get("pl") is None:
            continue
        symbol = trade.get("symbol", "UNKNOWN")
        asset_performance[symbol]["trades"] += 1
        asset_performance[symbol]["pl"] += trade.get("pl", 0.0)
        if trade.get("pl", 0) > 0:
            asset_performance[symbol]["wins"] += 1

    if asset_performance:
        top_assets = sorted(asset_performance.items(), key=lambda x: x[1]["pl"], reverse=True)[:5]
        dashboard += "| Symbol | Trades | Wins | Total P/L | Avg P/L | Win Rate |\n"
        dashboard += "|--------|--------|------|-----------|---------|----------|\n"
        for symbol, data in top_assets:
            win_rate_asset = (data["wins"] / data["trades"] * 100) if data["trades"] > 0 else 0.0
            avg_pl = data["pl"] / data["trades"] if data["trades"] > 0 else 0.0
            dashboard += f"| **{symbol}** | {data['trades']} | {data['wins']} | ${data['pl']:+,.2f} | ${avg_pl:+,.2f} | {win_rate_asset:.1f}% |\n"
    else:
        dashboard += "  (No asset performance data available)\n"

    dashboard += f"""
---

## üîÆ Predictive Analytics

### Monte Carlo Forecast (10,000 simulations)

| Horizon | Expected Profit | 95% Confidence Interval |
|---------|----------------|-------------------------|
| **7 Days** | ${forecast_dict.get("expected_profit_7d", 0.0):+,.2f} | ${forecast_dict.get("confidence_interval_95_lower", 0.0):+,.2f} to ${forecast_dict.get("confidence_interval_95_upper", 0.0):+,.2f} |
| **30 Days** | ${forecast_dict.get("expected_profit_30d", 0.0):+,.2f} | See 7-day CI scaled |

**Edge Drift Score**: {forecast_dict.get("edge_drift_score", 0.0):+.2f} ({"‚úÖ Improving" if forecast_dict.get("edge_drift_score", 0.0) > 0.1 else "‚ö†Ô∏è Decaying" if forecast_dict.get("edge_drift_score", 0.0) < -0.1 else "‚û°Ô∏è Stable"})
**Drawdown Probability (>5%)**: {forecast_dict.get("drawdown_probability", 0.0):.1f}%

---

## ‚öñÔ∏è Comprehensive Risk Metrics

"""

    # Calculate thresholds and formatted values before f-string
    sharpe_threshold = STAT_THRESHOLDS["sharpe_sortino"]
    sharpe_display = format_statistically_significant(
        risk_metrics_dict.get("sharpe_ratio", 0.0),
        sharpe_threshold,
        total_closed_trades,
        "{:.2f}",
    )
    sortino_display = format_statistically_significant(
        risk_metrics_dict.get("sortino_ratio", 0.0),
        sharpe_threshold,
        total_closed_trades,
        "{:.2f}",
    )

    dashboard += f"""| Metric | Value | Status |
|--------|-------|--------|
| **Max Drawdown** | {risk_metrics_dict.get("max_drawdown_pct", 0.0):.2f}% | {"‚úÖ" if risk_metrics_dict.get("max_drawdown_pct", 0.0) < 5.0 else "‚ö†Ô∏è" if risk_metrics_dict.get("max_drawdown_pct", 0.0) < 10.0 else "üö®"} |
| **Ulcer Index** | {risk_metrics_dict.get("ulcer_index", 0.0):.2f} | {"‚úÖ" if risk_metrics_dict.get("ulcer_index", 0.0) < 5.0 else "‚ö†Ô∏è"} |
| **Sharpe Ratio** | {sharpe_display} | {"‚úÖ" if total_closed_trades >= sharpe_threshold and risk_metrics_dict.get("sharpe_ratio", 0.0) > 1.0 else "‚ö†Ô∏è" if total_closed_trades >= sharpe_threshold and risk_metrics_dict.get("sharpe_ratio", 0.0) > 0.5 else ""} |
| **Sortino Ratio** | {sortino_display} | {"‚úÖ" if total_closed_trades >= sharpe_threshold and risk_metrics_dict.get("sortino_ratio", 0.0) > 1.0 else ""} |
| **Calmar Ratio** | {risk_metrics_dict.get("calmar_ratio", 0.0):.2f} | {"‚úÖ" if risk_metrics_dict.get("calmar_ratio", 0.0) > 1.0 else "‚ö†Ô∏è"} |
| **VaR (95%)** | {risk_metrics_dict.get("var_95", 0.0):.2f}% | Risk level |
| **VaR (99%)** | {risk_metrics_dict.get("var_99", 0.0):.2f}% | Extreme risk |
| **CVaR (95%)** | {risk_metrics_dict.get("cvar_95", 0.0):.2f}% | Expected tail loss |
| **Volatility (Annualized)** | {risk_metrics_dict.get("volatility", 0.0):.2f}% | {"‚úÖ" if risk_metrics_dict.get("volatility", 0.0) < 20.0 else "‚ö†Ô∏è"} |

**Note**: Sharpe/Sortino ratios require ‚â•{sharpe_threshold} closed trades for statistical significance. Current: {total_closed_trades} trades.

### Risk Heatmap

{generate_risk_heatmap(risk_metrics_dict)}

### üö® Risk Alerts

"""

    for alert in risk_alerts:
        dashboard += f"{alert}\n\n"

    # Add Strategy-Level Insights section
    dashboard += """---

## üìä Strategy-Level Insights

| Strategy | Win Rate | Expectancy | Avg Duration | Risk/Reward | Trades |
|----------|----------|------------|--------------|-------------|--------|
"""

    # Add strategy insights rows
    for strategy_name in ["Tier 1 Core", "Tier 2 Growth", "Tier 5 Crypto"]:
        if strategy_name in strategy_insights:
            insights = strategy_insights[strategy_name]
            win_rate_val = insights.get("win_rate")
            expectancy_val = insights.get("expectancy")
            avg_duration_val = insights.get("avg_duration_hours")
            risk_reward_val = insights.get("risk_reward_ratio")
            trade_count = insights.get("trade_count", 0)
            is_backtest = insights.get("is_backtest", False)

            # Format values with fallback for None
            if win_rate_val is not None:
                win_rate_str = f"{win_rate_val:.1f}%"
                if is_backtest:
                    win_rate_str += " (backtest)"
            else:
                win_rate_str = "Pending"

            if expectancy_val is not None:
                expectancy_str = f"${expectancy_val:+.2f}"
                if is_backtest:
                    expectancy_str += " (est)"
            else:
                expectancy_str = "Pending"

            if avg_duration_val is not None and avg_duration_val > 0:
                if avg_duration_val < 48:
                    duration_str = f"{avg_duration_val:.1f}h"
                else:
                    duration_str = f"{avg_duration_val / 24:.1f}d"
                if is_backtest:
                    duration_str += " (est)"
            else:
                duration_str = "Pending"

            if risk_reward_val is not None and risk_reward_val > 0:
                risk_reward_str = f"{risk_reward_val:.2f}"
                if is_backtest:
                    risk_reward_str += " (est)"
            else:
                risk_reward_str = "Pending"

            dashboard += f"| **{strategy_name}** | {win_rate_str} | {expectancy_str} | {duration_str} | {risk_reward_str} | {trade_count} |\n"

    dashboard += """
**Note**: Metrics marked with (backtest) or (est) are based on historical backtests pending live trade data.

---

## üìà Distributional Analysis

"""

    # Calculate distribution metrics from performance log
    if isinstance(perf_log, list) and len(perf_log) > 1:
        # Extract daily P/L values
        daily_pls = [entry.get("pl", 0.0) for entry in perf_log if entry.get("pl") is not None]

        if len(daily_pls) > 0:
            daily_pls_array = np.array(daily_pls)

            # Calculate distribution stats
            mean_pl = np.mean(daily_pls_array)
            median_pl = np.median(daily_pls_array)
            std_pl = np.std(daily_pls_array)

            # Win/Loss counts
            wins_dist = len([pl for pl in daily_pls if pl > 0])
            losses_dist = len([pl for pl in daily_pls if pl < 0])
            total_dist = len(daily_pls)

            # Win/Loss skew ratio
            avg_win = np.mean([pl for pl in daily_pls if pl > 0]) if wins_dist > 0 else 0.0
            avg_loss = np.mean([abs(pl) for pl in daily_pls if pl < 0]) if losses_dist > 0 else 0.0
            skew_ratio = avg_win / avg_loss if avg_loss > 0 else 0.0

            # Kurtosis (tail heaviness) - simplified indicator
            # Kurtosis > 3 = heavy tails, < 3 = light tails
            try:
                from scipy import stats

                kurtosis_val = stats.kurtosis(daily_pls_array, fisher=False)  # Pearson kurtosis
                tail_type = (
                    "Heavy tails"
                    if kurtosis_val > 3
                    else "Light tails"
                    if kurtosis_val < 3
                    else "Normal tails"
                )
            except (ImportError, Exception):
                kurtosis_val = 0.0
                tail_type = "Insufficient data"

            # Generate ASCII histogram
            if len(daily_pls) >= 5:
                # Create bins
                min_pl = np.min(daily_pls_array)
                max_pl = np.max(daily_pls_array)
                n_bins = min(20, len(daily_pls) // 2)

                if max_pl > min_pl:
                    bins = np.linspace(min_pl, max_pl, n_bins)
                    hist, bin_edges = np.histogram(daily_pls_array, bins=bins)
                    max_freq = np.max(hist) if len(hist) > 0 else 1

                    # Normalize to 8 levels for ASCII art
                    normalized_hist = (hist / max_freq * 8).astype(int)

                    # Create ASCII histogram using block characters
                    hist_chars = ["‚ñÅ", "‚ñÇ", "‚ñÉ", "‚ñÑ", "‚ñÖ", "‚ñÜ", "‚ñá", "‚ñà"]
                    ascii_hist = "".join([hist_chars[min(val, 7)] for val in normalized_hist])

                    dashboard += f"""**P/L Distribution**: {ascii_hist}

| Metric | Value |
|--------|-------|
| **Mean Daily P/L** | ${mean_pl:+.2f} |
| **Median Daily P/L** | ${median_pl:+.2f} |
| **Std Dev** | ${std_pl:.2f} |
| **Win/Loss Skew** | {skew_ratio:.2f}x {"(wins larger)" if skew_ratio > 1 else "(losses larger)" if skew_ratio < 1 else "(balanced)"} |
| **Tail Characteristics** | {tail_type} (Œ∫={kurtosis_val:.2f}) |
| **Win Days** | {wins_dist}/{total_dist} ({wins_dist / total_dist * 100:.1f}%) |
| **Loss Days** | {losses_dist}/{total_dist} ({losses_dist / total_dist * 100:.1f}%) |

**Interpretation**:
- **Win/Loss Skew {skew_ratio:.2f}x**: {"‚úÖ Average wins are larger than losses" if skew_ratio > 1.2 else "‚ö†Ô∏è Average losses are larger than wins" if skew_ratio < 0.8 else "‚û°Ô∏è Wins and losses are balanced"}
- **{tail_type}**: {"‚ö†Ô∏è Watch for outlier risk" if kurtosis_val > 3 else "‚úÖ Low outlier risk" if kurtosis_val < 3 else "Normal distribution"}

"""
                else:
                    dashboard += (
                        "  (Insufficient variation in P/L data for distribution analysis)\n\n"
                    )
            else:
                dashboard += "  (Collecting data... need 5+ days for distribution analysis)\n\n"
        else:
            dashboard += "  (Collecting data... no P/L values available yet)\n\n"
    else:
        dashboard += "  (Collecting data... performance log needs 2+ entries)\n\n"

    dashboard += """---

## üß† Psychological Indicators

"""

    # Calculate streaks from performance log
    current_streak = 0
    max_winning_streak = 0
    max_losing_streak = 0
    current_streak_type = None  # 'win' or 'loss'
    temp_win_streak = 0
    temp_loss_streak = 0

    if isinstance(perf_log, list) and len(perf_log) > 1:
        # Calculate streaks from daily P/L changes
        for i in range(1, len(perf_log)):
            prev_equity = perf_log[i - 1].get("equity", 100000.0)
            curr_equity = perf_log[i].get("equity", 100000.0)
            daily_change = curr_equity - prev_equity

            if daily_change > 0:  # Winning day
                temp_win_streak += 1
                temp_loss_streak = 0
                current_streak_type = "win"
            elif daily_change < 0:  # Losing day
                temp_loss_streak += 1
                temp_win_streak = 0
                current_streak_type = "loss"
            # If daily_change == 0, streak continues as-is

            max_winning_streak = max(max_winning_streak, temp_win_streak)
            max_losing_streak = max(max_losing_streak, temp_loss_streak)

        # Set current streak
        if current_streak_type == "win":
            current_streak = temp_win_streak
        elif current_streak_type == "loss":
            current_streak = -temp_loss_streak

    # Behavior under drawdown - check recent performance after drawdowns
    drawdown_behavior = "Building history..."
    if isinstance(perf_log, list) and len(perf_log) >= 10:
        # Find periods where we were in drawdown (equity below peak)
        peak_equity = 100000.0
        drawdown_recoveries = []
        in_drawdown = False
        drawdown_start_idx = 0

        for i, entry in enumerate(perf_log):
            equity = entry.get("equity", 100000.0)
            if equity > peak_equity:
                # New peak - check if we recovered from drawdown
                if in_drawdown:
                    recovery_days = i - drawdown_start_idx
                    drawdown_recoveries.append(recovery_days)
                    in_drawdown = False
                peak_equity = equity
            elif equity < peak_equity * 0.98 and not in_drawdown:
                # Entered drawdown (2% below peak)
                in_drawdown = True
                drawdown_start_idx = i

        if drawdown_recoveries:
            avg_recovery = sum(drawdown_recoveries) / len(drawdown_recoveries)
            drawdown_behavior = (
                f"Avg recovery: {avg_recovery:.1f} days ({len(drawdown_recoveries)} occurrences)"
            )
        else:
            drawdown_behavior = "No significant drawdowns (>2%) yet"

    # Equity vs Expected Equity
    equity_comparison = "Building history..."
    if isinstance(perf_log, list) and len(perf_log) >= 5:
        # Expected equity based on backtest: ~$0.28/day profit
        expected_daily_profit = 0.28
        trading_days = len(perf_log)
        expected_equity = 100000.0 + (expected_daily_profit * trading_days)
        actual_equity = current_equity
        equity_diff = actual_equity - expected_equity
        equity_diff_pct = (equity_diff / expected_equity) * 100

        equity_status = "‚úÖ" if equity_diff > 0 else "‚ö†Ô∏è" if equity_diff > -10 else "üö®"
        equity_comparison = f"${actual_equity:,.2f} vs ${expected_equity:,.2f} ({equity_diff:+.2f}, {equity_diff_pct:+.2f}%) {equity_status}"

    # Tilt Risk - based on recent losses and deviation from expected
    tilt_risk = "Low"
    tilt_status = "‚úÖ"
    if isinstance(perf_log, list) and len(perf_log) >= 5:
        # Check last 5 trading days
        recent_entries = perf_log[-5:]
        losing_days = 0
        total_loss = 0.0

        for i in range(1, len(recent_entries)):
            prev_equity = recent_entries[i - 1].get("equity", 100000.0)
            curr_equity = recent_entries[i].get("equity", 100000.0)
            daily_change = curr_equity - prev_equity

            if daily_change < 0:
                losing_days += 1
                total_loss += abs(daily_change)

        # High tilt risk if: 4+ losing days in last 5, or total loss > $50, or current losing streak > 3
        if losing_days >= 4 or total_loss > 50 or current_streak < -3:
            tilt_risk = "High"
            tilt_status = "üö®"
        elif losing_days >= 3 or total_loss > 25 or current_streak < -2:
            tilt_risk = "Medium"
            tilt_status = "‚ö†Ô∏è"

    # Current streak display
    if current_streak > 0:
        streak_display = f"{current_streak} wins"
        streak_status = "‚úÖ"
    elif current_streak < 0:
        streak_display = f"{abs(current_streak)} losses"
        streak_status = "üö®" if abs(current_streak) >= 3 else "‚ö†Ô∏è"
    else:
        streak_display = "0 (Starting)" if total_closed_trades == 0 else "0 (Neutral)"
        streak_status = "‚û°Ô∏è"

    dashboard += f"""| Indicator | Value | Status |
|-----------|-------|--------|
| **Current Streak** | {streak_display} | {streak_status} |
| **Max Winning Streak** | {max_winning_streak if max_winning_streak > 0 else "Building history..."} | {"‚úÖ" if max_winning_streak >= 3 else "‚û°Ô∏è"} |
| **Max Losing Streak** | {max_losing_streak if max_losing_streak > 0 else "Building history..."} | {"‚úÖ" if max_losing_streak < 3 else "‚ö†Ô∏è" if max_losing_streak < 5 else "üö®"} |
| **Behavior Under Drawdown** | {drawdown_behavior} | {"‚úÖ" if "No significant" in drawdown_behavior or ("Avg recovery" in drawdown_behavior and "days" in drawdown_behavior) else "‚û°Ô∏è"} |
| **Equity vs Expected** | {equity_comparison} | |
| **Tilt Risk** | {tilt_risk} | {tilt_status} |

**Notes**:
- **Current Streak**: Consecutive winning or losing days based on daily P/L changes
- **Max Streaks**: Historical peak winning/losing streaks (requires ‚â•10 days of data for significance)
- **Drawdown Behavior**: How quickly the system recovers from equity drawdowns (>2% from peak)
- **Equity vs Expected**: Actual equity compared to expected based on backtest ($0.28/day profit)
- **Tilt Risk**: Psychological risk indicator based on recent losses (High if 4+ losing days in last 5, or >$50 recent loss, or losing streak >3)

---

## ‚ö° Execution Quality

| Metric | Value | Status |
|--------|-------|--------|
| **Estimated Slippage** | <0.1% | ‚úÖ Tracking... |
| **Fill Rate** | ~100% | ‚úÖ Paper trading |
| **Average Spread Cost** | Tracking... | ‚è≥ Pending data |
| **Order Latency** | <100ms | ‚úÖ Cloud infrastructure |

**Note**: Execution quality metrics are estimated during paper trading. Real slippage and spread costs will be measured when live trading begins. Fill rate is near 100% in paper trading but may vary in live markets.

**Slippage Sources**:
- Market orders: Bid-ask spread + market impact
- Limit orders: Potential non-fill risk
- Volatility events: Wider spreads during high volatility

**Optimization Strategies**:
- Use limit orders for non-urgent entries
- Trade during market hours (9:30 AM - 4 PM ET) for better liquidity
- Monitor bid-ask spreads before order submission
- Consider VWAP/TWAP execution for larger positions

---

## üí∞ Tax Optimization & Compliance

**‚ö†Ô∏è CRITICAL FOR LIVE TRADING**: Tax implications can significantly impact net returns. This section tracks capital gains, day trading rules, and tax optimization opportunities.

### Pattern Day Trader (PDT) Rule Status

{pdt_status.get("status", "‚ö†Ô∏è Unable to calculate")}

| Metric | Value | Status |
|--------|-------|--------|
| **Day Trades (Last 5 Days)** | {pdt_status.get("day_trades_count", 0)} | {"üö®" if pdt_status.get("is_pdt", False) and not pdt_status.get("meets_equity_requirement", False) else "‚ö†Ô∏è" if pdt_status.get("day_trades_count", 0) >= 2 else "‚úÖ"} |
| **PDT Threshold** | 4+ day trades in 5 days | {"üö® VIOLATION RISK" if pdt_status.get("is_pdt", False) and not pdt_status.get("meets_equity_requirement", False) else "‚ö†Ô∏è APPROACHING" if pdt_status.get("day_trades_count", 0) >= 2 else "‚úÖ SAFE"} |
| **Minimum Equity Required** | $25,000 | {"üö®" if pdt_status.get("is_pdt", False) and not pdt_status.get("meets_equity_requirement", False) else "‚úÖ"} |
| **Current Equity** | ${current_equity:,.2f} | {"üö®" if pdt_status.get("is_pdt", False) and current_equity < 25000 else "‚úÖ"} |

**PDT Rule Explanation**: If you make 4+ day trades (same-day entry/exit) in 5 business days, you must maintain $25,000 minimum equity. Violations can result in account restrictions.

### Tax Impact Analysis

| Metric | Value |
|--------|-------|
| **Total Closed Trades** | {tax_metrics.get("total_trades", 0)} |
| **Day Trades** | {tax_metrics.get("day_trade_count", 0)} |
| **Short-Term Trades** | {tax_metrics.get("short_term_count", 0)} |
| **Long-Term Trades** | {tax_metrics.get("long_term_count", 0)} |
| **Wash Sales** | {tax_metrics.get("wash_sale_count", 0)} |
| **Gross Return** | ${tax_metrics.get("net_gain_loss", total_pl):+,.2f} |
| **Estimated Tax Liability** | ${tax_metrics.get("estimated_tax", 0.0):+,.2f} |
| **After-Tax Return** | ${tax_metrics.get("after_tax_return", total_pl):+,.2f} |
| **Tax Efficiency** | {tax_metrics.get("tax_efficiency", 1.0) * 100:.1f}% |

**Tax Rates**:
- **Short-Term Capital Gains** (< 1 year): {tax_metrics.get("short_term_tax_rate", 0.37) * 100:.0f}% (taxed as ordinary income)
- **Long-Term Capital Gains** (‚â• 1 year): {tax_metrics.get("long_term_tax_rate", 0.20) * 100:.0f}% (preferred rate)

**Key Tax Strategies**:
1. **Hold positions >1 year** for long-term capital gains rate (20% vs 37%)
2. **Avoid wash sales**: Don't repurchase same security within 30 days of selling at a loss
3. **Tax-loss harvesting**: Realize losses to offset gains before year-end
4. **Mark-to-Market Election (Section 475(f))**: Consider for active traders (treats trading as business income, exempts wash sale rule)

### Tax Optimization Recommendations

"""

    if tax_recommendations:
        for rec in tax_recommendations[:5]:
            dashboard += f"{rec}\n\n"
    else:
        dashboard += "‚úÖ **No immediate tax optimization recommendations**\n\n"

    dashboard += """
**Important Notes**:
- **Paper Trading**: Tax calculations are estimates. Actual tax liability depends on your tax bracket and state.
- **Wash Sale Rule**: Losses cannot be deducted if you repurchase the same security within 30 days before or after the sale.
- **Capital Loss Deduction**: Maximum $3,000 capital loss deduction per year (excess carries forward).
- **Day Trading**: Frequent day trading may trigger Pattern Day Trader (PDT) rules requiring $25k minimum equity.
- **Consult Tax Professional**: This is not tax advice. Consult a qualified tax professional before live trading.

**Integration with RL Pipeline**: Tax-aware reward function penalizes short-term gains and rewards long-term holdings to optimize after-tax returns.

"""

    # Benchmark comparison
    benchmark_section = ""
    try:
        from datetime import datetime as dt

        from src.utils.benchmark_comparison import BenchmarkComparator

        # Get start date from challenge or perf_log
        start_date_str = challenge_start.get("start_date", "")
        if not start_date_str and isinstance(perf_log, list) and perf_log:
            start_date_str = perf_log[0].get("date", "")

        if start_date_str:
            try:
                start_date = dt.fromisoformat(start_date_str.split("T")[0])
                end_date = dt.now()

                strategy_perf = {
                    "total_return_pct": (total_pl / starting_balance) * 100,
                    "sharpe_ratio": risk_metrics_dict.get("sharpe_ratio", 0.0),
                    "max_drawdown": risk_metrics_dict.get("max_drawdown_pct", 0.0),
                }

                comparator = BenchmarkComparator()
                comparison = comparator.compare_strategies(
                    strategy_perf, start_date, end_date, starting_balance
                )

                benchmark_section = "\n## üìä Benchmark Comparison\n\n"
                benchmark_section += "| Strategy | Total Return | Sharpe Ratio | Max Drawdown |\n"
                benchmark_section += "|----------|--------------|--------------|--------------|\n"

                # Strategy
                benchmark_section += f"| **Our Strategy** | {strategy_perf['total_return_pct']:+.2f}% | {strategy_perf['sharpe_ratio']:.2f} | {strategy_perf['max_drawdown']:.2f}% |\n"

                # SPY
                if "error" not in comparison.get("spy", {}):
                    spy = comparison["spy"]
                    benchmark_section += f"| **Buy-and-Hold SPY** | {spy.get('total_return_pct', 0):+.2f}% | {spy.get('sharpe_ratio', 0):.2f} | {spy.get('max_drawdown', 0):.2f}% |\n"

                # 60/40
                if "error" not in comparison.get("6040", {}):
                    perf_6040 = comparison["6040"]
                    benchmark_section += f"| **60/40 Portfolio** | {perf_6040.get('total_return_pct', 0):+.2f}% | {perf_6040.get('sharpe_ratio', 0):.2f} | {perf_6040.get('max_drawdown', 0):.2f}% |\n"

                # Comparison
                vs_spy = comparison.get("vs_spy", {})
                if vs_spy:
                    beats = "‚úÖ" if vs_spy.get("beats_spy", False) else "‚ùå"
                    benchmark_section += f"\n**vs SPY**: {beats} Return diff: {vs_spy.get('return_diff', 0):+.2f}% | Sharpe diff: {vs_spy.get('sharpe_diff', 0):+.2f}\n"

                benchmark_section += "\n---\n\n"
            except Exception as e:
                benchmark_section = f"\n‚ö†Ô∏è Benchmark comparison unavailable: {e}\n\n---\n\n"
    except ImportError:
        benchmark_section = "\n‚ö†Ô∏è Benchmark comparison requires yfinance\n\n---\n\n"
    except Exception as e:
        benchmark_section = f"\n‚ö†Ô∏è Benchmark comparison error: {e}\n\n---\n\n"

    dashboard += benchmark_section
    dashboard += f"""
---

## üß† AI-Generated Insights

### Daily Briefing

{enhanced_insights["summary"]}

**Key Findings**:
"""

    for finding in enhanced_insights["key_findings"][:5]:
        dashboard += f"- {finding}\n"

    if not enhanced_insights["key_findings"]:
        dashboard += "- No significant findings at this time\n"

    dashboard += """
**Recommendations**:
"""

    for rec in enhanced_insights["recommendations"][:5]:
        dashboard += f"- {rec}\n"

    if not enhanced_insights["recommendations"]:
        dashboard += "- Continue monitoring current strategy\n"

    dashboard += """
**Recent Trade Analysis**:
"""

    for trade_analysis in enhanced_insights["trade_analysis"][:5]:
        dashboard += f"- {trade_analysis}\n"

    if not enhanced_insights["trade_analysis"]:
        dashboard += "- No recent trades to analyze\n"

    dashboard += f"""
---

## üìà Equity Curve Visualization

```
{generate_equity_curve_chart(equity_curve) if len(equity_curve) > 1 else "  (Insufficient data for chart - need at least 2 data points)"}
```

"""

    if len(returns) > 3:
        dashboard += f"""### Returns Distribution

```
{generate_returns_distribution_chart(returns)}
```

"""

    dashboard += f"""
---

## üí∞ Financial Performance Summary

| Metric | Value |
|--------|-------|
| **Starting Balance** | ${starting_balance:,.2f} |
| **Current Equity** | ${current_equity:,.2f} |
| **Total P/L** | ${total_pl:+,.2f} ({total_pl / starting_balance * 100:+.2f}%) |
| **Total Trades** | {total_trades} |
| **Closed Trades** | {total_closed_trades} |
| **Winning Trades** | {winning_trades} |
| **Win Rate** | {win_rate:.1f}% |

---

## üìú Recent Trades (Last 7 Days)

"""

    # Get recent trades
    recent_trades_list = get_recent_trades(days=7)

    if recent_trades_list:
        dashboard += "| Date | Symbol | Side | Quantity | Price | Amount | Tier |\n"
        dashboard += "|------|--------|------|----------|-------|--------|------|\n"

        for trade in recent_trades_list[:15]:  # Show last 15 trades
            trade_date = trade.get("trade_date", trade.get("timestamp", "N/A"))
            if "T" in trade_date:  # If it's a timestamp, extract just the date
                trade_date = trade_date.split("T")[0]
            symbol = trade.get("symbol", "N/A")
            # Handle different field names for side/action
            side = trade.get("side", trade.get("action", "N/A")).upper()
            # Handle different field names for quantity
            qty = trade.get("qty", trade.get("quantity", 0))
            # Handle different field names for price
            price = trade.get("avg_price", trade.get("price", 0))
            # Calculate amount from notional or amount field or qty*price
            amount = trade.get("notional", trade.get("amount", qty * price if qty and price else 0))
            # Handle tier/strategy
            tier = trade.get("tier", trade.get("strategy", "N/A"))

            # Format numbers
            qty_str = f"{float(qty):.4f}" if qty else "N/A"
            price_str = f"${float(price):,.2f}" if price else "N/A"
            amount_str = f"${float(amount):,.2f}" if amount else "N/A"

            dashboard += f"| {trade_date} | {symbol} | {side} | {qty_str} | {price_str} | {amount_str} | {tier} |\n"

        if len(recent_trades_list) > 15:
            dashboard += f"\n*Showing 15 of {len(recent_trades_list)} trades from last 7 days*\n"
    else:
        dashboard += "*No trades recorded in the last 7 days*\n"

    dashboard += f"""
---

## üìä 90-Day R&D Challenge Progress

**Current**: Day {current_day} of {total_days} ({current_day / total_days * 100:.1f}% complete)

**Timeline Progress**: `{"‚ñà" * int((current_day / total_days * 100) / 5) + "‚ñë" * (20 - int((current_day / total_days * 100) / 5))}` ({current_day / total_days * 100:.1f}%)
*This shows how far through the 90-day R&D challenge timeline you are*

---

## üß† RAG Knowledge Base

**Powering AI-driven trading decisions with multiple data sources**

| Source | Records | Status | Last Update |
|--------|---------|--------|-------------|
| **Sentiment RAG** | {rag_stats["sentiment_rag"]["count"]} tickers | {rag_stats["sentiment_rag"]["status"]} | {rag_stats["sentiment_rag"]["last_update"]} |
| **Berkshire Letters** | {rag_stats["berkshire"]["count"]} PDFs ({rag_stats["berkshire"]["size_mb"]}MB) | {"‚úÖ Downloaded" if rag_stats["berkshire"]["count"] > 0 else "‚ö†Ô∏è Pending"} | {rag_stats["berkshire"]["year_range"]} |
| **Bogleheads Forum** | {rag_stats["bogleheads"]["insights"]} insights | {"‚úÖ Active" if rag_stats["bogleheads"]["insights"] > 0 else "‚è≥ " + rag_stats["bogleheads"]["status"]} | Daily |
| **YouTube Transcripts** | {rag_stats["youtube"]["transcripts"]} videos ({rag_stats["youtube"]["size_kb"]}KB) | {"‚úÖ Active" if rag_stats["youtube"]["transcripts"] > 0 else "‚ö†Ô∏è Empty"} | Daily |
| **Reddit Sentiment** | {rag_stats["reddit"]["count"]} files | {"‚úÖ Active" if rag_stats["reddit"]["count"] > 0 else "‚ö†Ô∏è Empty"} | Daily |
| **News Sentiment** | {rag_stats["news"]["count"]} files | {"‚úÖ Active" if rag_stats["news"]["count"] > 0 else "‚ö†Ô∏è Empty"} | Daily |

**Data Flow**: External Sources ‚Üí RAG Collectors ‚Üí Vector Store ‚Üí AI Analysis ‚Üí Trading Decisions

[View Full RAG Knowledge Base](RAG-Knowledge-Base) | [GitHub Actions](https://github.com/IgorGanapolsky/trading/actions/workflows/bogleheads-learning.yml)

---

## üîó Quick Links

- [Repository](https://github.com/IgorGanapolsky/trading)
- [GitHub Actions](https://github.com/IgorGanapolsky/trading/actions)
- [Latest Trades](https://github.com/IgorGanapolsky/trading/tree/main/data)
- [Trade Logs](https://github.com/IgorGanapolsky/trading/tree/main/data/trade_logs)

---

*This world-class dashboard is automatically updated daily by GitHub Actions with elite-level analytics.*
*Dashboard improvements: Enhanced trade analysis, performance attribution, actionable risk alerts, and better visualizations.*

"""

    return dashboard


def main():
    """Generate and save world-class dashboard."""
    dashboard = generate_world_class_dashboard()

    # Save to file
    output_file = Path("wiki/Progress-Dashboard.md")
    output_file.parent.mkdir(exist_ok=True)

    with open(output_file, "w") as f:
        f.write(dashboard)

    print("‚úÖ World-class dashboard generated successfully!")
    print(f"üìÑ Saved to: {output_file}")

    return 0


if __name__ == "__main__":
    sys.exit(main())
